{"cells":[{"cell_type":"markdown","id":"2649a290-03ed-445a-90aa-18c517674f3e","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"cognitiveclass.ai logo\"\u003e\n","\u003c/center\u003e\n","\n","\u003c!-- # Financial services: Lab 1. Cryptocurrency Dataset Creation  (on the example of BTC/BUSD), calculation and analysis of technical financial indicators, characterizing the cryptocurrency market (on the example of ADOSC, NATR, TRANGE) --\u003e\n","\n","# **Investigation relationships between exchange rate BTC/BUSD and ADOSC, NATR, TRANGE indicators**\n","    \n","## Lab 1. Dataset Creation\n","    \n","Estimated time needed: **30** minutes\n","\n","\n","### The tasks:\n","*   Download and process statistical time series of cryptocurrency pair BTC/BUSD, describing the dynamics of the cryptocurrency market;\n","*   Upload statistical data from the Pandas library;\n","*   Calculate and analyze technical financial indicators for cryptocurrecy market (on the example of ADOSC, NATR,TRANGE)\n","\n","\n","### Objectives\n","\n","After completing this lab you will be able to:\n","\n","*  Acquire data in various ways\n","*  Obtain insights from data with Pandas library \n","*  Resample data\n","*  Calculate Indicators for cryptocurrency market analysis \n","   \n","\n","\n","\u003ch3\u003eTable of Contents\u003c/h3\u003e\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\u003col\u003e\n","    \u003cli\u003eData Acquisition\u003c/li\u003e\n","        \u003cul\u003e\n","            \u003cli\u003eRead Data\u003c/li\u003e\n","            \u003cli\u003eResample Data\u003c/li\u003e\n","        \u003c/ul\u003e\n","    \u003cli\u003eFinancial Indicators\u003c/li\u003e\n","        \u003cul\u003e\n","            \u003cli\u003eADOSC\u003c/li\u003e\n","            \u003cli\u003eNATR\u003c/li\u003e\n","            \u003cli\u003eTRANGE\u003c/li\u003e\n","        \u003c/ul\u003e\n","    \u003cli\u003eBasic Insight of Dataset\u003c/li\u003e\n","        \u003cul\u003e\n","            \u003cli\u003eData Types\u003c/li\u003e\n","            \u003cli\u003eDescribe\u003c/li\u003e\n","            \u003cli\u003eInfo\u003c/li\u003e\n","            \u003cli\u003eSave Dataset\u003c/li\u003e\n","        \u003c/ul\u003e\n","\u003c/ol\u003e\n","\n","\u003c/div\u003e\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"819c45c6-5d4a-4d8a-911d-f7dcea213143","metadata":{},"outputs":[],"source":["## 1. Data Acquisition\n","\u003cp\u003e\n","There are various formats for a dataset: \u003ccode\u003e.csv\u003c/code\u003e, \u003ccode\u003e.json\u003c/code\u003e, \u003ccode\u003e.xlsx\u003c/code\u003e  etc. The dataset can be stored in different places, on your local machine or sometimes online.\u003cbr\u003e\n","\n","In this section, you will learn how to load a dataset into our Jupyter Notebook.\u003cbr\u003e\n","\n","In our case, the dataset is an online source, and it is in a \u003cem\u003e\u003cstrong\u003eCSV (comma separated value) format\u003c/strong\u003e\u003c/em\u003e. Let's use this dataset as an example to practice data reading.\n","\n","\u003cul\u003e\n","    \u003cli\u003eData source: \u003ca href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0QGDEN/BTCBUSD_trades.csv\" target=\"_blank\"\u003ehttps://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0QGDEN/BTCBUSD_trades.csv\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003eData type: csv\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","The Pandas Library is a useful tool that enables us to read various datasets into a dataframe. Our Jupyter notebook platforms have a built-in \u003cb\u003ePandas Library\u003c/b\u003e so that all we need to do is import Pandas without installing.\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"9663b270-3d77-47d8-84d4-15dac028b1f3","metadata":{},"outputs":[],"source":["If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"]},{"cell_type":"code","id":"aceb20df-0176-4137-a5cb-cbefff6df0be","metadata":{},"outputs":[],"source":["#install specific version of libraries used in  lab\n#! mamba install pandas -y\n#! mamba install numpy -y"]},{"cell_type":"code","id":"bdb7b5a5-5438-4bf0-a561-56993189891b","metadata":{},"outputs":[],"source":["# import pandas library\nimport pandas as pd\nimport numpy as np"]},{"cell_type":"markdown","id":"f1124950-01cc-4958-a655-e5464ca26d00","metadata":{},"outputs":[],"source":["### Read Data\n","\u003cp\u003e\n","We use \u003ccode\u003epandas.read_csv()\u003c/code\u003e function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.\u003cbr\u003e\n","\n","You can also assign the dataset to any variable you create.\n","\n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"bb65c72c-62c7-4fbe-83cb-1cb5785a2d6d","metadata":{},"outputs":[],"source":["path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0QGDEN/BTCBUSD_trades.csv\""]},{"cell_type":"markdown","id":"40c0730f-1c99-4d95-8b9b-ee446f56e62d","metadata":{},"outputs":[],"source":["This dataset was hosted on IBM Cloud object. Click \u003ca href=\"https://cocl.us/DA101EN_object_storage?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\"\u003eHERE\u003c/a\u003e for free storage.\n"]},{"cell_type":"code","id":"9013128c-044e-42e8-afce-ef8ac8ef4b43","metadata":{},"outputs":[],"source":["# Read the online file by the URL provides above, and assign it to variable \"df\"\ndf = pd.read_csv(path)"]},{"cell_type":"markdown","id":"184bb6b9-595d-47d0-8812-99cbe8b3b555","metadata":{},"outputs":[],"source":["In finance you sometimes need to use different numbers of decimal places. For ease of reading, let's specify the value of the precision parameter equal to 3 to display three decimal signs (instead of 6 as default).\n"]},{"cell_type":"code","id":"d1231313-b7d7-47fa-8b03-0242ce53761a","metadata":{},"outputs":[],"source":["pd.set_option(\"display.precision\", 3)"]},{"cell_type":"markdown","id":"c401624a-b6f9-44c5-9224-68489aa6a97e","metadata":{},"outputs":[],"source":["After reading the dataset, we can use the \u003ccode\u003edataframe.head(n)\u003c/code\u003e method to check the top \u003cem\u003e\u003cstrong\u003en\u003c/strong\u003e\u003c/em\u003e rows of the dataframe, where n is an integer. Contrary to \u003ccode\u003edataframe.head(n)\u003c/code\u003e, \u003ccode\u003edataframe.tail(n)\u003c/code\u003e will show you the bottom \u003cem\u003e\u003cstrong\u003en\u003c/strong\u003e\u003c/em\u003e rows of the dataframe.\n"]},{"cell_type":"code","id":"4b9526a8-9ea0-4487-b951-a241aa232818","metadata":{},"outputs":[],"source":["# show the first 5 rows using dataframe.head() method\nprint(\"The first 5 rows of the dataframe\")\ndf.head(5)"]},{"cell_type":"markdown","id":"b772d387-ef9d-4c9f-b2a4-40940aab9279","metadata":{},"outputs":[],"source":["As there is no text (i.e. column title) on the first cell of the CSV file, the resulting data frame's first column is given the name \u003ccode\u003eUnnamed:0\u003c/code\u003e. We should fix this issue.\n","\n","By specifying an \u003ccode\u003eindex_col=0\u003c/code\u003e argument to \u003ccode\u003eread_csv()\u003c/code\u003e function we tell pandas that the first column in the CSV file is the index for the data frame. As follows, the undesired column \u003ccode\u003eUnnamed:0\u003c/code\u003e will disappear.\n"]},{"cell_type":"code","id":"3428fd6c-6b60-407d-ac02-8ca430d21ebb","metadata":{},"outputs":[],"source":["df = pd.read_csv(path, index_col=0)\ndf.head(5)"]},{"cell_type":"markdown","id":"0439757e-8714-4f17-a79c-aae893b6432a","metadata":{},"outputs":[],"source":["The dataset can be quickly processed to a time series analysis if it is indexed by date. Furthermore, it is the correct option when it comes to time series visualization.\n","\n","We need to set our \u003cstrong\u003e'ts'\u003c/strong\u003e column representing a date as an index column. We use \u003ccode\u003edf.set_index(inplace=True)\u003c/code\u003e method to set the dataframe index using existing column. The \u003ccode\u003einplace=True\u003c/code\u003e parameter in this function means to modify the dataframe and save the changes.\n","\n","Last but not least, the set index in our dataframe should be converted do datetime index type. This we accomplish using \u003ccode\u003epd.to_datetime()\u003c/code\u003e method. To obtain the current index of our dataframe use \u003ccode\u003edf.index\u003c/code\u003e method.\n"]},{"cell_type":"code","id":"714b509f-e93f-4183-a2bc-2484158d514c","metadata":{},"outputs":[],"source":["df.set_index('ts', inplace=True)\ndf.index = pd.to_datetime(df.index)\ndf.head()"]},{"cell_type":"markdown","id":"535a1a95-1cce-41d1-bebb-990fa6aa245b","metadata":{},"outputs":[],"source":["### Resample Data\n","\n","Since the data in our dataset is not aggregated, we need to convert it to aggregated data for further analysis. The \u003cem\u003eresampling technique\u003c/em\u003e will provide a helpful hand in this.\n","\n","### Resampling\n","\n","\u003ch4\u003eWhat is resampling?\u003c/h4\u003e\n","\n","For time series analysis, \u003cstrong\u003eresampling\u003c/strong\u003e is an essential technique that gives you the freedom to select the required level of data resolution. For example, you can upsample data or add more data points by converting 5-minute data into 1-minute data, and vice versa, downsample it.\n","\u003cbr\u003e\n","\u003cp\u003e\n","    The basic syntax for resampling is \u003ccode\u003edataframe.resample('desired resolution')\u003c/code\u003e method. Along with that, different aggregation function can be used.\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"0bd88128-e9e7-4c88-8fd7-f2f48e52d5dd","metadata":{},"outputs":[],"source":["In our case, the dataset provided has nonaggregated data, such missing the needed **OHLCV parameters** for a given period.\n","\n","\u003ch4\u003eWhat is OHLCV?\u003c/h4\u003e\n","\n","**OHLCV** is an aggregated form of market data standing for **Open, High, Low, Close and Volume**. OHLCV data includes 5 data points: the Open and Close represent the first and the last price level during a specified interval. High and Low represent the highest and lowest reached price during that interval. Volume is the total amount traded during that period.\n","Read more about this topic \u003ca href=\"https://www.kaiko.com/collections/ohlcv?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003ehere\u003c/a\u003e.\n","\n","\n","We need to transform data from non-aggregated to data within a 1-minute interval.\n","\n","Considering the semantics of our dataset, for the **Open** parameter, we take \u003cem\u003ethe first value\u003c/em\u003e of an price interval, while for **Close**, we have \u003cem\u003ethe last value\u003c/em\u003e. \n","For **High** \u003cem\u003emaximum value\u003c/em\u003e within an interval is taken, in accordance for **Low** we take \u003cem\u003eminimum price value\u003c/em\u003e. \n","Column **Volume** will store all \u003cem\u003esummed-up values\u003c/em\u003e within an interval. \n","The **Price** parameter will represent a \u003cem\u003emean price value\u003c/em\u003e within an interval.  \n"]},{"cell_type":"markdown","id":"75aaf01d-191c-4149-b812-cecd7759e3c3","metadata":{},"outputs":[],"source":["Let's implement data resampling to 1-minute interval.\n"]},{"cell_type":"code","id":"1638c8a9-254d-4a12-abbe-43b86a52d29d","metadata":{},"outputs":[],"source":["# adding new columns\ndf['count'] = df['volume']\nfor column in ['open', 'high', 'close', 'low']:\n    df[column] = df['price']\n\n# resampling to 1-minute interval\ndf = df.loc[:, 'bs':'low'].resample('1min').agg({\n    'bs': 'first',\n    'price': 'mean',\n    'volume': 'sum',\n    'count': 'count',\n    'open': 'first',\n    'high': 'max',\n    'close': 'last',\n    'low': 'min',\n})\n\ndf.head()"]},{"cell_type":"markdown","id":"e6395b22-52ec-440b-b1d4-a5be737dedb5","metadata":{},"outputs":[],"source":["Notice that now the data in the index column is distributed over an 1-minute interval as well as other parameters.\n","\n","Great! As a result, we moved to aggregated data.\n"]},{"cell_type":"markdown","id":"2c5c76fb-34d9-4fb8-9c5b-fe63ff013bad","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","  \u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #1:\u003c/b\u003e\n","\n","  \u003cb\u003eCheck the bottom 10 rows of data frame \"df\".\u003c/b\u003e \n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"dac3725d-3795-4aa8-87b1-21a3f7ce5ad3","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \nprint(\"The last 10 rows of the dataframe\\n\")\ndf.tail(10)"]},{"cell_type":"markdown","id":"809ba5be-f72d-4418-b745-9388495717f6","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","print(\"The last 10 rows of the dataframe\\n\")\n","df.tail(10)\n","```\n"]},{"cell_type":"markdown","id":"fe494e0c-744a-438c-8889-5d78bb34d1fb","metadata":{},"outputs":[],"source":["## 2. Financial Indicators\n"]},{"cell_type":"markdown","id":"95463a58-993c-46bb-a3e4-06a45d475aa2","metadata":{},"outputs":[],"source":["Cryptocurrencies are traded every day of the week, around-the-clock. This generates a tremendous volume of data, which makes it difficult to know what to watch out for and how to separate the signal from the noise. Together with candlestick charts, indicators give traders tools to streamline data and spot patterns for better trading decisions. Read more \u003ca href=\"https://www.bcbgroup.com/best-indicators-for-crypto-trading-analysis/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003ehere\u003c/a\u003e.\n","\u003ch3\u003eWhat are indicators?\u003c/h3\u003e\n","\n","\u003cstrong\u003eIndicators\u003c/strong\u003e are statistics used to measure current conditions as well as to forecast financial or economic trends.\n","\n","In the context of technical analysis, an indicator is a mathematical calculation based on a security's price or volume. The result is used to predict future prices. Read more \u003ca href=\"https://www.investopedia.com/terms/i/indicator.asp?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003ehere\u003c/a\u003e.\n"]},{"cell_type":"markdown","id":"34fbef0f-0b11-4ac9-a7b7-395d554dff8c","metadata":{},"outputs":[],"source":["### ADOSC - Chaikin A/D Oscillator\n"]},{"cell_type":"markdown","id":"2ca181c5-6bcc-48bb-b7aa-53f75b574e60","metadata":{},"outputs":[],"source":["\u003ci\u003e$The\\ Chaikin\\ advance/decline\\ (AD)$\u003c/i\u003e is a volume-based indicator to measure the cumulative flow of money into and out of an asset. The indicator assumes that the degree of buying or selling pressure can be determined by the location of the close, relative to the high and low for the period. Read more \u003ca href=\"https://www.investopedia.com/terms/c/chaikinoscillator.asp?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003ehere\u003c/a\u003e.\n"]},{"cell_type":"markdown","id":"1c26424d-0a11-44a7-acaf-d035260f2bc0","metadata":{},"outputs":[],"source":["$The\\ AD\\ line$ is a running total of each period's \u003cb\u003e$ money\\ flow\\ volume\\  (MFV)$ \u003c/b\u003e. It is calculated as follows: \n","\n","1. Compute the \u003cb\u003e$ money\\ flow\\ multiplier\\  MFM$ \u003c/b\u003e as the relationship of the close to the high-low range: \u003cbr\u003e\n","\n","$$\n","MFM = \\frac{(Close \\ - Low) \\ - \\ (High \\ - Close)}{High \\ - \\ Low}\n","$$\n","\n","2. Multiply the $MFM$ by the period's volume  $Volume$ to come up with the $MFV$: \n","\n","$$\n","MFV =  MFM \\times Volume\n","$$\n","\n","3. Obtain the $AD\\ line$:\n","\n","$$\n","AD = AD_p + MFV,\n","$$\n","\u003ccenter\u003ewhere $p$ — previous\u003c/center\u003e\n"]},{"cell_type":"markdown","id":"cfa1fa14-6ceb-479e-9c34-80bba99036ed","metadata":{},"outputs":[],"source":["\u003cb\u003e$The\\ Chaikin\\ A/D\\ oscillator\\ (ADOSC)$\u003c/b\u003e \u003ci\u003e(read more at \u003ca href=\"https://www.investopedia.com/articles/active-trading/031914/understanding-chaikin-oscillator.asp?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eADOSC\u003c/a\u003e\u003c/i\u003e) is the \n","\u003ca href=\"https://www.investopedia.com/terms/m/macd.asp?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eMACD indicator\u003c/a\u003e that's applied to \u003cb\u003e$the\\ Chaikin\\ AD\\ line$\u003c/b\u003e. The Chaikin oscillator intends to predict changes in the AD line.\n","It is computed as the difference between 3 and 10 \u003ca href=\"https://www.investopedia.com/terms/e/ema.asp?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eEMA\u003c/a\u003e periods of the AD line.\n","\n","$$\n","ADOSC\\ =\\ EMA_{3}\\ −\\ EMA_{10}\n","$$\n"]},{"cell_type":"markdown","id":"4a30dd89-0341-4d75-a6c4-3e5465d9dd04","metadata":{},"outputs":[],"source":["Let's declare the function responsible of calculating the Chaikin Oscillator value and create separate column in our data frame to store the result.\n"]},{"cell_type":"code","id":"61035786-09fc-45b2-a331-90b1e9a31950","metadata":{},"outputs":[],"source":["def ema(s: pd.Series, period: int) -\u003e pd.Series:\n    \"\"\"Return the exponential moving average (EMA).\n    \"\"\"\n    return s.ewm(span=period, min_periods=period, adjust=False).mean()\n\n\ndef adosc(df: pd.DataFrame) -\u003e pd.Series:\n    \"\"\"Return the Chaikin Oscillator.\n    \"\"\"\n    # calculate money flow multiplier:\n    mfm = ((df['close'] - df['low']) - (df['high'] - df['close'])) / (df['high'] - df['low'])\n    \n    # calculate money flow volume:\n    mfv = mfm * df['volume']\n\n    # refine money flow volume:\n    mfv = np.where((df['close'] == df['high']) \u0026 (df['close'] == df['low']) | (df['high'] == df['low']), 0, mfv)\n    mfv = pd.Series(mfv, index=df.index)\n\n    # calculate A/D line:\n    ad = mfv.cumsum()\n\n    # Calculate Chaikin Oscillator:\n    chaikin = ema(ad, 3) - ema(ad, 10)\n    return chaikin"]},{"cell_type":"code","id":"22a17a95-8221-49af-9a07-34c9db777f73","metadata":{},"outputs":[],"source":["df['adosc_indicator'] = adosc(df)\ndf[['adosc_indicator']].head(15)"]},{"cell_type":"markdown","id":"45ae9581-a7a7-4696-9ca0-7f8bce4beb07","metadata":{},"outputs":[],"source":["You may have noticed that the first 9 rows contain `NaN` values. It happens because the Chaikin oscillator is computed as the difference between EMA periods of the AD line. As the longest minimum EMA period we set was the 10-minute interval, the first 9 entries have not needed data to be calculated.\n","\n","Secondly, we may also observe values less than zero in the obtained data. The Chaikin Oscillator turns positive when the faster 3-minute EMA moves above the slower 10-minute EMA. Conversely, the indicator turns negative when the 3-minute EMA moves below the 10-minute EMA. Read more \u003ca href=\"https://school.stockcharts.com/doku.php?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\u0026id=technical_indicators%3Achaikin_oscillator\"\u003ehere\u003c/a\u003e.\n"]},{"cell_type":"markdown","id":"11981880-3d33-425a-b00f-ca7b79050b0b","metadata":{},"outputs":[],"source":["### ATR Normalized (NATR)\n"]},{"cell_type":"markdown","id":"b7555bea-357e-4e3f-a633-61b44ba3c3e6","metadata":{},"outputs":[],"source":["\u003ci\u003e$ATR\\ Normalized\\ (NATR)$\u003c/i\u003e is an instrument, which is used in the technical analysis for measuring the volatility level. In contrast to other modern and popular indicators it is not used for identifying the direction of price movement. It is used only for measuring the volatility level, especially the volatility, which is caused by price gaps or slow refreshing of the chart. \n","\n","\u003ca href=\"https://support.atas.net/en/knowledge-bases/2/articles/43436-atr-normalized?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eATR Normalized\u003c/a\u003e is a normalized version of the \u003ca href=\"https://www.investopedia.com/terms/a/atr.asp?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eATR indicator\u003c/a\u003e and is calculated according to the following formula:\n","\u003cbr\u003e\n","\u003cbr\u003e\n","$$ \n","NATR =  \\frac{{100}\\times ATR}{Close} \\\\\\\\\\\\\\\\\n","\\\\\\\\\\\\\n","$$\n","To calculate ATR we need to perform the following steps:\n","\n","1. Calculate $True\\ Range\\ (TR)$:\n","$$\n","TR = \\textrm{max}[(High\\ - \\ Low),\\ |High\\ - \\ Close_p|,\\ |Low\\ - \\ Close_p|],\n","$$\n","\u003ccenter\u003ewhere $p$ — previous\u003ccenter\u003e\n","\n","2. Calculate $ATR_{p}$:\n","$$\n","ATR_p = \\frac{1}{n} \\sum \\limits _{i=1} ^{n} TR_i,\n","$$ \n","\u003ccenter\u003ewhere $n$ — the time period employed, $p$ — previous\u003ccenter\u003e\n","    \n","2. Calculate $ATR$:\n","$$\n","ATR = \\frac{ATR_p(n \\ - \\ 1)\\ + \\ TR}{n}\n","$$\n"]},{"cell_type":"markdown","id":"8c4bae9d-07d9-4b96-a976-98d2fc9dc657","metadata":{},"outputs":[],"source":["Let's declare the function responsible of calculating the ATR indicator values and create separate column in our data frame to store the result.\n"]},{"cell_type":"code","id":"b897bea0-52fb-40ef-b719-b371565287c9","metadata":{},"outputs":[],"source":["def natr(df: pd.DataFrame, period: int = 15) -\u003e pd.Series:\n    \"\"\"Return the ATR Normalized (NATR) indicator.\n    \"\"\"\n    # calculate values\n    high, low, close = df['high'], df['low'], df['close']\n    \n    high_low = high - low\n    high_close = np.abs(high - close.shift())\n    low_close = np.abs(low - close.shift())\n    \n    # calculate True Range\n    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n    true_range = np.max(ranges, axis=1)\n    \n    # calculate previous ATR\n    atr_prev = true_range.rolling(period).sum() / period\n    \n    # calculate current ATR\n    atr = (atr_prev*(period - 1) + true_range) / period\n    \n    # normalize ATR \n    natr = (100 * atr) / df['close']\n    return natr"]},{"cell_type":"code","id":"6611950b-b6b6-4065-898d-01955536a4c8","metadata":{},"outputs":[],"source":["df['natr_indicator'] = natr(df)\ndf[['natr_indicator']].head(20)"]},{"cell_type":"markdown","id":"88f54871-046b-4f04-b4fa-0e0699d35bde","metadata":{},"outputs":[],"source":["Once more, we observe `NaN` values in the first 14 rows of obtained data. Since the ATR is a moving average of the true ranges in a specific period \u003ci\u003e(in our case 15-minute interval)\u003c/i\u003e, the first 14 entries have not needed data to be calculated and are filled with `NaN` values.\n"]},{"cell_type":"markdown","id":"9cd06786-9013-475b-916d-8cb2a93cd8f5","metadata":{},"outputs":[],"source":["### True Range (TRANGE)\n"]},{"cell_type":"markdown","id":"0b97bf6e-135a-414c-8443-34c33f150471","metadata":{},"outputs":[],"source":["\u003ci\u003e$True\\ Range\\ (TRANGE)$\u003c/i\u003e is a technical indicator which measures the daily range plus any gap from the closing price of the preceding day.\n","\n","True Range is calculated as the greater of:\n","\n","\u003cul\u003e\n","\u003cli\u003e\u003cem\u003eHigh for the period\u003c/em\u003e less \u003cem\u003ethe Low for the period\u003c/em\u003e\u003c/li\u003e\n","\u003cli\u003e\u003cem\u003eHigh for the period\u003c/em\u003e less \u003cem\u003ethe Close for the previous period\u003c/em\u003e\u003c/li\u003e\n","\u003cli\u003e\u003cem\u003eClose for the previous period\u003c/em\u003e and \u003cem\u003ethe Low for the current period\u003c/em\u003e\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","The formula which find the maximum among the specified values is:\n","\u003cbr\u003e\n","\u003cbr\u003e\n","$$\n","TR = \\textrm{max}[(High_p\\ - \\ Low_p),\\ |High_p\\ - Close_{p-1}|,\\ |Low_p\\ - \\ Close_{p-1}|],\n","$$\n","\u003ccenter\u003ewhere $p$ — current period\u003ccenter\u003e\n"]},{"cell_type":"markdown","id":"ee3206d7-4cf4-4264-bc43-fe9c44d71b28","metadata":{},"outputs":[],"source":["Let's declare the function responsible of calculating the TRANGE indicator values and create separate column in our data frame to store the result.\n"]},{"cell_type":"code","id":"86154cfd-951f-4eee-9b00-6bed78224859","metadata":{},"outputs":[],"source":["def trange(df: pd.DataFrame) -\u003e pd.Series:\n    \"\"\"Return the True Range (TRANGE) indicator.\n    \"\"\"\n    # calculate values\n    high, low, close = df['high'], df['low'], df['close']\n    \n    high_low = high - low\n    high_close = np.abs(high - close.shift())\n    low_close = np.abs(low - close.shift())\n    \n    # calculate maximum of obtained values\n    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n    true_range = np.amax(ranges, axis=1)\n    true_range[0] = np.nan\n    return true_range"]},{"cell_type":"code","id":"2e142288-1eaa-4efe-9691-a760958f88b1","metadata":{},"outputs":[],"source":["df['trange_indicator'] = trange(df)\ndf[['trange_indicator']].head(15)"]},{"cell_type":"markdown","id":"dbc24e99-1b8f-4ff5-b17e-9d094ddc37ba","metadata":{},"outputs":[],"source":["Notice that for calculating TRANGE previous period is also considered. As a result, the first row contains `NaN` value. \n"]},{"cell_type":"markdown","id":"e177605e-3b38-443a-95e7-999ef9fdc467","metadata":{},"outputs":[],"source":["### Add Headers\n","\u003cp\u003e\n","If we do not specify the header of our dataset by passing an argument \u003ccode\u003eheaders = None\u003c/code\u003e inside the \u003ccode\u003eread_csv()\u003c/code\u003e method, Pandas automatically sets it with an integer starting from 0.\n","\u003c/p\u003e\n","\u003cp\u003e\n","To better describe our data, it is a best practice to introduce a header. \n","Information of dataset we are using is available \u003ca href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0QGDEN/BTCBUSD_trades.csv\" target=\"_blank\"\u003eHERE\u003c/a\u003e.\n","\u003c/p\u003e\n","\u003cp\u003e\n","Thus, if headers are absent, we have to add them manually. Let's learn how to deal with it.\n","\u003c/p\u003e\n","\u003cp\u003e\n","First, we create a list \"headers\" that includes all column names in order.\n","Then, we use \u003ccode\u003edataframe.columns = headers\u003c/code\u003e to replace the headers with the list we created.\n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"14a812fe-359b-408d-b607-53f0b91dd928","metadata":{},"outputs":[],"source":["# create headers list\nheaders = [\"BS\", \"Price\", \"Volume\", \"Count\", \"Open\", \"High\", \"Close\", \"Low\", 'ADOSC', 'NATR', 'TRANGE']\nprint(\"headers\\n\", headers)"]},{"cell_type":"markdown","id":"a35298b8-f8ca-488b-97ee-a5d3bc4baebb","metadata":{},"outputs":[],"source":["We replace headers and recheck our dataframe:\n"]},{"cell_type":"code","id":"3cf6a32c-8c05-4416-86f3-496977f547a9","metadata":{},"outputs":[],"source":["df.columns = headers\ndf.head(10)"]},{"cell_type":"markdown","id":"712014d1-8efe-4a46-9f9c-1cd8a7ae65a1","metadata":{},"outputs":[],"source":["It is also possible to change the name of the index columns. Use \u003ccode\u003edf.index.names\u003c/code\u003e method to initialize new names.\n"]},{"cell_type":"code","id":"d05d4090-6faf-4356-8bd6-dbb85d9168cf","metadata":{},"outputs":[],"source":["df.index.names = ['Time']\ndf.head(10)"]},{"cell_type":"markdown","id":"44773da7-1efa-42e5-af60-3da46e050974","metadata":{},"outputs":[],"source":["Excellent! Our dataframe has transformed in a positive way. Now the headers are clear and concise.\n"]},{"cell_type":"markdown","id":"10f90dc8-e5e8-4364-b40a-ca6aee178f44","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #2:\u003c/b\u003e    \n","\n","\u003cb\u003eDelete the \"BS\" column of the dataframe. Use `df.drop('column_name', axis=1, inplace=True)` method, where `'column_name'` stands for name of the column to be removed.\u003c/b\u003e\n","\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"8d247a75-4a50-4425-a2d4-026d02c7f7a1","metadata":{},"outputs":[],"source":["\u003cstrong\u003e\u003cem\u003eNote:\u003c/em\u003e\u003c/strong\u003e \u003ccode\u003eaxis=1\u003c/code\u003e parameter means dropping columns, whereas \u003ccode\u003eaxis=0\u003c/code\u003e is used for rows.\u003ccode\u003einplace=True\u003c/code\u003e parameter means doing operation inplace and modifying current dataframe.\n"]},{"cell_type":"code","id":"802da39f-2844-4cd1-b062-1131099d6afe","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \ndf.drop('BS', axis=1, inplace=True)\ndf.head()"]},{"cell_type":"markdown","id":"d6f7cef9-9000-43e8-bccd-55070ddb69b0","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","df.drop('BS', axis=1, inplace=True)\n","df.head()\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"8d47321f-1d80-4c3b-9d8b-71a6019da26c","metadata":{},"outputs":[],"source":["## 3. Basic Insight of Dataset\n","\u003cp\u003e\n","After reading data into Pandas dataframe, it is time for us to explore the dataset.\u003cbr\u003e\n","There are several ways to obtain essential insights of the data to help us better understand our dataset.\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"5ffc0870-7e80-44af-b18f-7b5a9a047b91","metadata":{},"outputs":[],"source":["## Data Types\n","\u003cp\u003e\n","Data has a variety of types.\u003cbr\u003e\n","\n","The main types stored in Pandas dataframes are \u003cstrong\u003eobject\u003c/strong\u003e, \u003cstrong\u003efloat\u003c/strong\u003e, \u003cstrong\u003eint\u003c/strong\u003e, \u003cstrong\u003ebool\u003c/strong\u003e and \u003cstrong\u003edatetime\u003c/strong\u003e. In order to better learn about each attribute, it is always good for us to know the data type of each column. In Pandas to return series with the data type of each column of dataframe \u003ccode\u003e.dtypes\u003c/code\u003e is used.\n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"8103ef26-3718-45e2-a50a-68fde672bb9f","metadata":{},"outputs":[],"source":["# check the data type of data frame \"df\" by .dtypes\nprint(df.dtypes)"]},{"cell_type":"markdown","id":"8e8c17ad-4fec-4cb1-9900-a4796d01a2d8","metadata":{},"outputs":[],"source":["\u003cp\u003e\n","As shown above, it is clear to see that the data type of \"Open\", \"High\", \"Low\", \"Close\", \"Price\", and \"Volume\" are \u003ccode\u003efloat64\u003c/code\u003e, and \"Count\" is \u003ccode\u003eint64\u003c/code\u003e, etc.\n","\u003c/p\u003e\n","\u003cp\u003e\n","These data types can be changed. We will learn how to accomplish this in a later module.\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"dabdefb7-54c7-4792-9ac9-1aa8fde9df94","metadata":{},"outputs":[],"source":["## Describe\n","\n","If we would like to get a statistical summary of each column e.g. \u003cem\u003ecount\u003c/em\u003e, \u003cem\u003ecolumn mean value\u003c/em\u003e, \u003cem\u003ecolumn standard deviation\u003c/em\u003e., etc., we use the describe method:\n"]},{"cell_type":"raw","id":"30232913-94bf-473f-9908-ef068de1c843","metadata":{},"outputs":[],"source":["dataframe.describe()"]},{"cell_type":"markdown","id":"4dc48707-bc46-408e-85f0-37dd44bb868f","metadata":{},"outputs":[],"source":["This method will provide various summary statistics, excluding \u003ccode\u003eNaN\u003c/code\u003e (Not a Number) values.\n"]},{"cell_type":"code","id":"b8c990cc-1526-4d8d-9f2b-33014bf5bd11","metadata":{},"outputs":[],"source":["# get a statistical summary of each column of dataframe using .describe()\ndf.describe()"]},{"cell_type":"markdown","id":"084cb34d-bd0c-406b-9e2a-7f59dc0859a6","metadata":{},"outputs":[],"source":["\u003cp\u003e\n","This shows the statistical summary of all numeric-typed (int, float) columns.\u003cbr\u003e\n","\n","For example, the attribute \"Count\" has 18056 counts, the mean value of this column is 27.188, the standard deviation is 16.389, the minimum value is 0, 25th percentile is 15, 50th percentile is 25, 75th percentile is 38, and the maximum value is 100.\u003cbr\u003e\n","\n","However, what if we would also like to check all the columns including those that are of type *object*? \u003cbr\u003e\u003cbr\u003e\n","You can add an argument \u003ccode\u003einclude=\"all\"\u003c/code\u003e inside the bracket. Let's try it again.\n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"3a7facf4-8527-4cf9-8e65-5e7d1dcd8acb","metadata":{},"outputs":[],"source":["# describe all the columns in \"df\"\ndf.describe(include=\"all\")"]},{"cell_type":"markdown","id":"ceaa873d-fe2f-43cf-9554-ecbec642ab22","metadata":{},"outputs":[],"source":["\u003cp\u003e\n","Now it provides the statistical summary of all the columns, including object-typed attributes. As our dataframe has not got any object-typed columns the  results are the same.\u003cbr\u003e\n","\n","However, If we had ones, we could see how many unique values there, which one is the top value and the frequency of top value in the object-typed columns. In addition, some object-typed values in the summary table can be shown as `NaN`. This is because those numbers are not available regarding a particular column type.\u003cbr\u003e\n","\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"44619984-1376-4658-bc17-aa7e4f2a24c5","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\n","\u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #3:\u003c/b\u003e \n","\n","\u003cp\u003e\n","You can select the columns of a dataframe by indicating the name of each column. For example, you can select the three columns as follows:\n","\u003c/p\u003e\n","\u003cp\u003e\n","    \u003ccode\u003edataframe[['column 1',column 2', 'column 3']]\u003c/code\u003e\n","\u003c/p\u003e\n","\u003cp\u003e\n","    Where \u003cstrong\u003e'column'\u003c/strong\u003e is the name of the column, you can apply the method  \u003ccode\u003e.describe()\u003c/code\u003e to get the statistics of those columns as follows:\n","\u003c/p\u003e\n","\u003cp\u003e\n","    \u003ccode\u003edataframe[['column 1',column 2', 'column 3'] ].describe()\u003c/code\u003e\n","\u003c/p\u003e\n","\n","Apply the \u003ccode\u003e.describe()\u003c/code\u003e method to the columns \u003cstrong\u003e'Count'\u003c/strong\u003e and \u003cstrong\u003e'Price'\u003c/strong\u003e.\n","\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"0e23faa1-17d7-4cce-af00-fda2fb342e3b","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute\ndf[['Count', 'Price']].describe()"]},{"cell_type":"markdown","id":"32321994-1346-4e6b-9b66-8b900038e502","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","df[['Count', 'Price']].describe()\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"9ad81f47-ec78-4364-9b09-35f3a77747d8","metadata":{},"outputs":[],"source":["## Info\n","\n","Another method you can use to check your dataset is:\n"]},{"cell_type":"raw","id":"20de2ee1-ea67-484f-bcff-a847eebbe13f","metadata":{},"outputs":[],"source":["dataframe.info()"]},{"cell_type":"markdown","id":"c8c293f2-f65c-4077-990b-0188c008a009","metadata":{},"outputs":[],"source":["It provides a concise summary of your DataFrame.\n","\n","This method prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n"]},{"cell_type":"code","id":"0964ab97-d549-4b32-974f-413580301a4f","metadata":{},"outputs":[],"source":["# look at the info of \"df\"\ndf.info()"]},{"cell_type":"markdown","id":"0964e090-86b9-4110-bd4f-30245eaa241f","metadata":{},"outputs":[],"source":["## Save Dataset\n","\u003cp\u003e\n","Correspondingly, Pandas enables us to save the dataset to csv. By using the \u003ccode\u003edataframe.to_csv()\u003c/code\u003e method, you can add the file path and name along with quotation marks in the brackets.\n","\u003c/p\u003e\n","\u003cp\u003e\n","For example, if you would save the dataframe \u003cstrong\u003edf\u003c/strong\u003e as \u003cstrong\u003eBTCBUSD_trades_1m.csv\u003c/strong\u003e to your local machine, you may use the syntax below, where \u003ccode\u003eindex=True\u003c/code\u003e means the row names will be written as well.\n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"90c7a544-638c-4afd-b9da-84cf78489404","metadata":{},"outputs":[],"source":["df.to_csv(\"BTCBUSD_trades_1m.csv\", index=True)"]},{"cell_type":"markdown","id":"7b2e02f6-f47f-4c2e-bf91-b88e2da1b4ba","metadata":{},"outputs":[],"source":["We can also read and save other file formats. We can use similar functions like `pd.read_csv()` and `df.to_csv()` for other data formats. The functions are listed in the following table:\n"]},{"cell_type":"markdown","id":"df80f5cd-6c3f-452e-8e41-5f2a040a857e","metadata":{},"outputs":[],"source":["## Read/Save Other Data Formats\n","\n","| Data Formate |        Read       |            Save |\n","| ------------ | :---------------: | --------------: |\n","| csv          |  `pd.read_csv()`  |   `df.to_csv()` |\n","| json         |  `pd.read_json()` |  `df.to_json()` |\n","| excel        | `pd.read_excel()` | `df.to_excel()` |\n","| hdf          |  `pd.read_hdf()`  |   `df.to_hdf()` |\n","| sql          |  `pd.read_sql()`  |   `df.to_sql()` |\n","| ...          |        ...        |             ... |\n"]},{"cell_type":"markdown","id":"d5029b64-430e-4040-99fa-35182316ff6a","metadata":{},"outputs":[],"source":["## Excellent! You have just completed the notebook!\n"]},{"cell_type":"markdown","id":"be9fa6ba-088d-4436-9fee-d5abaaf2552b","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","## Authors\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaryna_beida?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eYaryna Beida\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eProf. Yaroslav Vyklyuk, DrSc, PhD\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\"\u003eProf. Mariya Fleychuk, DrSc, PhD\u003c/a\u003e\n","\n","\n","## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By   | Change Description                                         |\n","| ----------------- | ------- | -------------| ---------------------------------------------------------- |\n","|     2023-02-25    |   1.0   | Yaryna Beida | Lab created                                                |\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2023. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}