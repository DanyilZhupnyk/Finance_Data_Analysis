{"cells":[{"cell_type":"markdown","id":"3fe843b2-26d4-4a11-b8e4-71b9182d670a","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"cognitiveclass.ai logo\"\u003e\n","\u003c/center\u003e\n","\n","# **Investigation relationships between exchange rate BTC/BUSD and ADOSC, NATR, TRANGE indicators**\n","\n","## Lab 3. Data Analysis with Python\n","\n","Estimated time needed: **30** minutes\n","\n","\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","    \n","Для Марії\n","### The tasks:\n","*   \n","\n","\u003c/div\u003e\n","\n","### Objectives\n","\n","After completing this lab you will be able to:\n","\n","*   Explore features or charecteristics to predict price of cryptocurrency\n","*   Visualizes cryptocurrency dynamics using Candlestick Chart\n","*   Estimate high or low relationships level between cryptocurrency charecteristics and indicators\n","*   Perform financial statistic tests\n","\n","\u003ch3\u003eTable of Contents\u003c/h3\u003e\n","\n","\u003cdiv class=\"alert alert-block alert-info\" style=\"margin-top: 20px\"\u003e\n","\u003col\u003e\n","    \u003cli\u003eImport and Load Data\u003c/li\u003e\n","    \u003cli\u003eAnalyzing Individual Feature Patterns using Visualization\u003c/li\u003e\n","    \u003cli\u003eDescriptive Statistical Analysis\u003c/li\u003e\n","    \u003cli\u003eBasics of Grouping\u003c/li\u003e\n","    \u003cli\u003eCorrelation and Causation\u003c/li\u003e\n","    \u003cli\u003eANOVA\u003c/li\u003e\n","    \u003cli\u003eDurbin Watson Test\u003c/li\u003e\n","    \u003cli\u003eGranger Causality Test\u003c/li\u003e\n","\u003c/ol\u003e\n","\n","\u003c/div\u003e\n","\u003chr\u003e\n"]},{"cell_type":"markdown","id":"d5af4625-b8ee-495e-a967-8a6785ed737b","metadata":{},"outputs":[],"source":["## Dataset Description\n","\n","### Context\n","Dataset contains historical changes of the ***BTC/BUSD*** and ***ADOSC, NATR, TRANGE indicators*** for the period from *11/11/2022 to 11/24/2022* with an *1-minute* aggregation time.\n","\n","### Columns\n","\n","#### Input columns\n","* ***Time*** - the timestamp of the record\n","* ***Open*** -  the price of the asset at the beginning of the trading period\n","* ***High*** -  the highest price of the asset during the trading period\n","* ***Low*** - the lowest price of the asset during the trading period.\n","* ***Close*** - the price of the asset at the end of the trading period\n","* ***Volume*** - the total number of shares or contracts of a particular asset that are traded during a given period\n","* ***Count*** -  the number of individual trades or transactions that have been executed during a given time period\n","* ***ADOSC*** - Chaikin oscillator indicator\n","* ***NATR*** - normalized average true range (ATR) indicator\n","* ***TRANGE*** - true range indicator\n","\n","#### Target column\n","* ***Price*** - the average price at which a particular asset has been bought or sold during a given period\n"]},{"cell_type":"markdown","id":"3fabe711-a844-4a97-baf6-f0bd84c8e08d","metadata":{},"outputs":[],"source":["----\n"]},{"cell_type":"markdown","id":"32d5c9b2-e7f7-4c99-bc92-d437c4ad5901","metadata":{},"outputs":[],"source":["## 1. Import and Load Data\n"]},{"cell_type":"markdown","id":"4c6048ec-fbcb-4aca-b54a-6dc97468f716","metadata":{},"outputs":[],"source":["### Setup\n"]},{"cell_type":"markdown","id":"78239e2f-9464-4ee2-a451-ff4f5334cd60","metadata":{},"outputs":[],"source":["If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"]},{"cell_type":"code","id":"82416031-6f3d-4989-8437-572f8a58a7a0","metadata":{},"outputs":[],"source":["#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n#install specific version of libraries used in lab\n#! mamba install pandas==1.3.3\n#! mamba install numpy=1.21.2\n#! mamba install scipy=1.7.1-y\n#!  mamba install seaborn=0.9.0-y\n! conda install -c conda-forge mplfinance -y\n! conda install -c conda-forge astropy -y"]},{"cell_type":"markdown","id":"3399f762-711e-44dc-9766-98b2adcb083f","metadata":{},"outputs":[],"source":["Import libraries:\n"]},{"cell_type":"code","id":"0d6090ea-5815-4b1a-931f-7012c5119eb3","metadata":{},"outputs":[],"source":["import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom typing import List\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\nfrom statsmodels.stats.stattools import durbin_watson\nfrom statsmodels.tsa.stattools import grangercausalitytests\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport mplfinance as fplt\n%matplotlib inline \nfrom astropy.visualization import astropy_mpl_style\nimport itertools\nfrom itertools import combinations\nfrom IPython.display import display"]},{"cell_type":"markdown","id":"6d657c14-a55a-4b4d-9e4e-0c282a33b55d","metadata":{},"outputs":[],"source":["### Load Data\n"]},{"cell_type":"markdown","id":"c9914fc6-68dd-4499-9736-3bcfe29f6758","metadata":{},"outputs":[],"source":["First, we assign the URL of the dataset to \u003ccode\u003e\"path\"\u003c/code\u003c\u003e.\n"]},{"cell_type":"code","id":"407d7adc-4f2e-4671-8a15-ca0db7aadceb","metadata":{},"outputs":[],"source":["path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX043BEN/BTCBUSD_trades_1m.csv\""]},{"cell_type":"markdown","id":"34c7af0a-3c24-4e84-8528-6c6508db8545","metadata":{},"outputs":[],"source":["Use the Pandas method \u003ccode\u003eread_csv()\u003c/code\u003e to load the data from the web address. Set the parameter  \u003ccode\u003eindex_col=0\u003c/code\u003e in order to use the first column of cvs file as the index of the dataframe.\n"]},{"cell_type":"code","id":"e9e181f1-19bb-4736-8957-ebcf7ded3506","metadata":{},"outputs":[],"source":["df = pd.read_csv(path, index_col=0)"]},{"cell_type":"markdown","id":"dfdc7263-4864-4c88-926c-a84e1f728f83","metadata":{},"outputs":[],"source":["Set dataframe index column type to \u003cstrong\u003edatetime\u003c/strong\u003e using \u003ccode\u003epd.to_datetime()\u003c/code\u003e method for correct time series analysis. \n"]},{"cell_type":"code","id":"623e78fe-1e8b-4c6a-9f4c-c26704efb8ac","metadata":{},"outputs":[],"source":["df.index = pd.to_datetime(df.index)"]},{"cell_type":"markdown","id":"708fa6d0-d3a9-4cf6-ac3f-51460bbff74a","metadata":{},"outputs":[],"source":["In the previous lab we calculated technical financial indicators. Since the values of previous periods had to be taken into account for their calculation, the first few lines of the dataframe contain `NaN` values.\n","\n","We will use different methods for recovering missing data in this module that do not work correctly with recovering data in the first rows of time series. Therefore, we need to remove `NaN` values with `df.dropna(inplace=True)` method.\n"]},{"cell_type":"code","id":"7eed5e2c-114d-42ef-9915-099dbd3b5971","metadata":{},"outputs":[],"source":["df.dropna(inplace=True)\ndf.head()"]},{"cell_type":"markdown","id":"90d66180-c419-4cd9-9372-de1b7e6cb336","metadata":{},"outputs":[],"source":["Let's check the dimensionality of our dataframe.\n"]},{"cell_type":"code","id":"8eadaaae-5a13-474a-80dd-e51c606fbacd","metadata":{},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","id":"54c13545-4f06-4e2d-b5d0-1286ad7467c3","metadata":{},"outputs":[],"source":["## 2. Analyzing Individual Feature Patterns Using Visualization\n"]},{"cell_type":"markdown","id":"4ce8cb1f-6998-4ed0-8374-51be30b32431","metadata":{},"outputs":[],"source":["#### How to choose the right visualization method?\n","\u003cp\u003eWhen visualizing individual variables, it is important to first understand what type of variable you are dealing with. This will help us find the right visualization method for that variable.\u003c/p\u003e\n"]},{"cell_type":"code","id":"f8c58398-7641-4db6-a9e6-49f2684688c3","metadata":{},"outputs":[],"source":["# list the data types for each column\nprint(df.dtypes)"]},{"cell_type":"markdown","id":"c9e2f123-a923-40f0-bce4-e7f32e61bdbb","metadata":{},"outputs":[],"source":["As you can see, all columns have correct types regarding their meanings. \n"]},{"cell_type":"markdown","id":"865e8e2a-2fd0-4851-8a60-0ecf5b7d4a12","metadata":{},"outputs":[],"source":["### Candlestick visualization\n"]},{"cell_type":"markdown","id":"d50901ba-db04-4988-89d3-ea72304b975c","metadata":{},"outputs":[],"source":["\u003cp\u003eA type of financial chart called a \u003cstrong\u003ecandlestick chart\u003c/strong\u003e is used to show how the price of a security, derivative, or currency has changed over time.\n","\u003c/p\u003e\n","\n","Each candlestick contains all four crucial pieces of information for that day: open and close in the thick body; high and low in the \"candle wick.\" This makes it similar to a bar chart. Due to its high information density, it frequently depicts trade trends over brief periods of time, such as a few days or trading sessions.\n"]},{"cell_type":"markdown","id":"c17ad5e3-0de7-4abd-88c4-17931849b8d1","metadata":{},"outputs":[],"source":["#### Candlestick chart for cryptocurrency\n","\n","A candlestick displays the change in an asset's price over time and it is ideal for our case. Each candlestick, which serves as the fundamental indicator in a crypto chart, depicts a \u003cem\u003eparticular price movement\u003c/em\u003e, including \u003cem\u003ethe opening\u003c/em\u003e and \u003cem\u003eclosing values\u003c/em\u003e as well as \u003cem\u003ethe highest\u003c/em\u003e and \u003cem\u003elowest price points\u003c/em\u003e.\n"]},{"cell_type":"markdown","id":"7662b82c-4780-497d-a40e-b5a71cb5c5d6","metadata":{},"outputs":[],"source":["\u003ccenter\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX043BEN/candlestick_chart.png\" width=\"400,\" height=\"500\"\u003e\n","\u003c/center\u003e\n","More about candlestick chart read \u003ca href=\"https://en.wikipedia.org/wiki/Candlestick_chart?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX043BEN2378-2023-01-01\"\u003ehere\u003c/a\u003e.\n"]},{"cell_type":"markdown","id":"81701aa3-ad7b-4811-bc35-5e874092306b","metadata":{},"outputs":[],"source":["As we checked before, our dataframe has more than 16000 rows. It is too huge to visualize the entire time period of the price movement. To deal with, it we perform \u003cem\u003e\u003cstrong\u003edata resampling\u003c/strong\u003e\u003c/em\u003e from the previous module.\n"]},{"cell_type":"markdown","id":"4bcca255-67f5-4f41-ad1e-49679a3654da","metadata":{},"outputs":[],"source":["Let's downsample the series from 1-minute into 1-day intervals.\n"]},{"cell_type":"code","id":"1cbc5c6d-9b8f-47a5-9c72-4cff569d342a","metadata":{},"outputs":[],"source":["df_candlestick = df.copy()\n\ndf_candlestick = df_candlestick.loc[:, 'Price':'Low'].resample(\"1D\").agg({\n    'Open': 'first',\n    'High': 'max',\n    'Close': 'last',\n    'Low': 'min',\n    'Volume': 'sum',\n    'Count': 'sum',\n    'Price': 'mean'\n})\ndf_candlestick.head()"]},{"cell_type":"markdown","id":"c4abcef6-e2d0-4d4b-b417-2f8a665bf769","metadata":{},"outputs":[],"source":["Now let's plot candlesticks for BTCBUSD currency.\n"]},{"cell_type":"code","id":"deabe4f8-9025-40a3-ae69-7b7db5feab16","metadata":{},"outputs":[],"source":["df_candlestick.columns = ['open', 'high', 'low', 'close', 'volume', 'count', 'price']\nfplt.plot(\n            df_candlestick,\n            type='candle',\n            style='charles',\n            title='BTCBUSD',\n            ylabel='Price (BUSD)'\n        )"]},{"cell_type":"markdown","id":"d7ef6482-0995-4216-b461-bb8c01de6e6b","metadata":{},"outputs":[],"source":["From this candlestick chart, we can follow the historical prices of an BTCBUSD asset, obtaining a good summary of the price's behavior.\n"]},{"cell_type":"markdown","id":"2146b08c-96fa-4db8-9346-9f02e1b7b166","metadata":{},"outputs":[],"source":["\u003ccode\u003emplfinance\u003c/code\u003e library also provides a function to display the amount of stocks traded on that day. You can display the volume chart below the candlestick chart by simply passing the \u003ccode\u003evolume=True\u003c/code\u003e to the \u003ccode\u003eplot()\u003c/code\u003e method. You can also pass ylabel_lower to change the y-axis label of the volume chart.\n","\n","#### Why do we need volume in a candlestick chart?\n","\n","The higher the trading volume, the wider the candlestick. On low-volume days, the candlesticks will be thinner. Volume is also displayed at the bottom of the chart as a series of rectangles. Red volume bars are low-price days, and green bars are high-price days.\n"]},{"cell_type":"code","id":"6fbd2ef8-bebf-43ae-b300-ae621d8358fd","metadata":{},"outputs":[],"source":["fplt.plot(\n            df_candlestick,\n            type='candle',\n            style='charles',\n            title='BTCBUSD',\n            ylabel='Price',\n            volume=True,\n            ylabel_lower='Volume',\n            )"]},{"cell_type":"markdown","id":"f3199921-bacf-4b09-beaa-242644d4da60","metadata":{},"outputs":[],"source":["### Correlation\n"]},{"cell_type":"markdown","id":"2360d59d-4b16-45fb-9630-fab94c09e7e6","metadata":{},"outputs":[],"source":["#### What is a correlation?\n","\n","A statistical measure known as \u003cstrong\u003ecorrelation\u003c/strong\u003e expresses how closely two variables are related linearly (meaning they change together at a constant rate). It's a typical technique for describing straightforward connections without explicitly stating cause and effect.\n"]},{"cell_type":"markdown","id":"972ed950-116a-44e6-857f-bfcd4c4f3d75","metadata":{},"outputs":[],"source":["We can calculate the correlation between different variables. For instance, for types \u003ccode\u003eint64\u003c/code\u003e or \u003ccode\u003efloat64\u003c/code\u003e using the method \u003ccode\u003ecorr()\u003c/code\u003e:\n"]},{"cell_type":"raw","id":"7cc06e71-9023-4b3c-9ce0-10802bbb3040","metadata":{},"outputs":[],"source":["dataframe.corr()"]},{"cell_type":"markdown","id":"01603ff4-1406-4031-a726-55bdfaeeb45e","metadata":{},"outputs":[],"source":["Let's calculate the correlation for BTCBUSD currency paramters and its indicators.\n"]},{"cell_type":"code","id":"4b96ca2a-0099-4b6d-b95b-0af529d98590","metadata":{},"outputs":[],"source":["# find correlation\ncorr = df.corr()\ncorr"]},{"cell_type":"markdown","id":"debb34c7-faef-4cb5-b80b-56efac31dd64","metadata":{},"outputs":[],"source":["#### How to interpret correlation results?\n"]},{"cell_type":"markdown","id":"32137d63-fa8f-4655-b6fc-1597f1ff2ffe","metadata":{},"outputs":[],"source":["The magnitude of the correlation coefficient indicates the strength of the association. A correlation of -1.0 indicates a perfect negative correlation, and a correlation of 1.0 indicates a perfect positive correlation. If the correlation coefficient is greater than zero, it is a positive relationship. Conversely, if the value is less than zero, it is a negative relationship.\n"]},{"cell_type":"markdown","id":"69793380-f9d6-4a60-a45d-40af2d126b34","metadata":{},"outputs":[],"source":["To better understand the concept of correlation we should visualize the strength of relationships between numerical variables using \u003cb\u003ecorrelation heatmaps\u003c/b\u003e. \n","\n","#### What is Correlation Heatmap?\n","\n","\u003cstrong\u003eCorrelation heatmaps\u003c/strong\u003e are a type of plot that visualize the strength of relationships between numerical variables. \n","\n","Correlation plots are used to understand which variables are related to each other and the strength of this relationship.\n"]},{"cell_type":"code","id":"1cbcf565-49e9-44d3-9943-401c3dea07d7","metadata":{},"outputs":[],"source":["sns.heatmap(corr)"]},{"cell_type":"markdown","id":"8f214562-54f8-4ba2-8c6d-1d15d24a95e9","metadata":{},"outputs":[],"source":["#### How do you interpret a correlation heatmap?\n","\n","Correlation ranges from -1 to +1. Values closer to 0 means there is no linear trend between the two variables. The closer the correlation is to 1, the more positively associated they are. The diagonal elements are always one. \n","\n"," From the heatmap, it can be seen that the most correlated among the indicators for the price of our cryptocurrency are the Volume and NATR parameters. However, their correlation values are not that high.\n"]},{"cell_type":"markdown","id":"ed77aef8-8885-423f-ab9e-696c61402ec2","metadata":{},"outputs":[],"source":["We will study correlation more precisely (Pearson correlation in-depth) at the end of the notebook.\n"]},{"cell_type":"markdown","id":"47e351ba-8684-4f34-be8e-bc3d6240409c","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #1:\u003c/b\u003e\n","\n","\u003cp\u003eFind the correlation between the BTCBUSD currency \u003cstrong\u003ePrice\u003c/strong\u003e and its \u003cstrong\u003eVolume, ADOSC, NATR, TRANGE indicators\u003c/strong\u003e columns. \n","\n","Build heatmap to understand the resuluts more precisely.\u003c/p\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"e391a4d5-41e5-430d-bc49-1b4462cee41e","metadata":{},"outputs":[],"source":["\u003cstrong\u003e\u003cem\u003eNote:\u003c/em\u003e\u003c/strong\u003e if you would like to select certain columns, use the following syntax: \u003ccode\u003edf[['Price','Volume', 'ADOSC', 'NATR', 'TRANGE']]\u003c/code\u003e.\n"]},{"cell_type":"code","id":"13603eae-40c7-4cc2-9df5-89432d80e9e4","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute\n\n# find correlation\ncorr = df[['Price', 'Volume', 'ADOSC', 'NATR', 'TRANGE']].corr()\ncorr"]},{"cell_type":"markdown","id":"cab77f4e-8cbe-4c4b-a1b0-ee509e0c2cdb","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# find correlation\n","corr = df[['Price', 'Volume', 'ADOSC', 'NATR', 'TRANGE']].corr()\n","corr\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"code","id":"cf2984ca-8a5a-4212-9dbc-6f9684fd8ac8","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute\n\n# build heatmap\nsns.heatmap(corr, annot=True)"]},{"cell_type":"markdown","id":"f9c95675-a1d4-4627-88ca-aaf4063c8a0c","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# build heatmap\n","sns.heatmap(corr, annot=True)\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"4fb8953c-7304-47db-bccf-000f0a5f4e3d","metadata":{},"outputs":[],"source":["The Volume and NATR parameters are the two price indicators for our coin that have the highest correlation, as can be seen from the heatmap. Their correlation values are not very great, though.\n","It is also noticeable how the parameters NATR and TRANGE are highly correlated with Volume. They can be useful for determining his future performance.\n"]},{"cell_type":"markdown","id":"89baa50f-df59-40d2-8dbb-96d1814bff85","metadata":{},"outputs":[],"source":["### Continuous Numerical Variables\n","\n","#### What are Continuous numerical variables?\n","\n","\u003cp\u003e\u003cstrong\u003eContinuous numerical variables\u003c/strong\u003e are variables that may contain any value within some range. They can be of type \u003ccode\u003eint64\u003c/code\u003e or \u003ccode\u003efloat64\u003c/code\u003e. A great way to visualize these variables is by using scatterplots with fitted lines.\u003c/p\u003e\n","\n","\u003cp\u003eIn order to start understanding the \u003cem\u003elinear relationship\u003c/em\u003e between an individual variable and the price, we can use \u003ccode\u003eregplot\u003c/code\u003e which plots the \u003cstrong\u003escatterplot\u003c/strong\u003e plus the fitted regression line for the data.\u003c/p\u003e\n","\n","\u003cpre\u003e\n","\u003cstrong\u003eA scatter plot\u003c/strong\u003e is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data.\n","\u003c/pre\u003e\n"]},{"cell_type":"markdown","id":"4eecc093-fada-4d87-bd8e-4538f1755243","metadata":{},"outputs":[],"source":["Let's see several examples of different linear relationships:\n"]},{"cell_type":"markdown","id":"85e68662-0ca5-498e-9c39-3c815e960e5a","metadata":{},"outputs":[],"source":["#### Weak Linear Relationship\n"]},{"cell_type":"markdown","id":"7070e165-7ed2-4a84-9fdd-1e8bf8e201de","metadata":{},"outputs":[],"source":["Firstly, we declare custom \u003ccode\u003eregplot()\u003c/code\u003e function responsible of plotting linear regression.\n"]},{"cell_type":"code","id":"0ca5e714-58e2-4cdb-9923-61c1d4ff739b","metadata":{},"outputs":[],"source":["def regplot(pd: pd.DataFrame, x: str, y: str) -\u003e None:\n    \"\"\" Return data plot and a linear regression model fit.\n    \"\"\"\n    sns.regplot(x=x, y=y, data=pd)\n    plt.ylim(0,)\n\n    plt.xlabel(f\"{x}, BUSD\")\n    plt.ylabel(f\"{y}, BUSD\")\n    plt.show()"]},{"cell_type":"markdown","id":"47c7c27d-99e5-4e19-91da-70a5743bc846","metadata":{},"outputs":[],"source":["Let's find the scatterplot of BTCBUSD price and Volume. \n"]},{"cell_type":"code","id":"2a460770-4ee7-425e-b375-46deddf8c879","metadata":{},"outputs":[],"source":["# Open Volume as potential predictor variable of BTCBUSD price\nregplot(df, 'Price', 'Volume')"]},{"cell_type":"markdown","id":"b1245629-b3ed-4d93-b5e3-1a57ee296647","metadata":{},"outputs":[],"source":["\u003cp\u003eVolume does not seem like a good predictor of the price at all since the regression line is close to horizontal. Also, the data points are very scattered and far from the fitted line, showing lots of variability. Therefore, it's not a reliable variable.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"3c07b4f1-9701-4cfe-b67e-a6f82c93b242","metadata":{},"outputs":[],"source":["We can examine the correlation between BTCBUSD price and Volume and see that it's approximately -0.0915.\n"]},{"cell_type":"code","id":"2906cafc-7925-437b-8128-aff377957c1c","metadata":{},"outputs":[],"source":["df[[\"Price\", \"Volume\"]].corr()"]},{"cell_type":"markdown","id":"586bc0d4-eb59-425e-afeb-f7793edba90b","metadata":{},"outputs":[],"source":["#### Positive Linear Relationship\n"]},{"cell_type":"markdown","id":"75610a6e-2ff8-4feb-9872-4ec43ee88d05","metadata":{},"outputs":[],"source":["TRANGE may be a potential predictor variable of Volume. Let's find the scatterplot of \"TRANGE\" and \"Volume\".\n"]},{"cell_type":"code","id":"c0a7f91a-d02b-4188-a8cd-fac0d546a01a","metadata":{},"outputs":[],"source":["regplot(df, 'Volume', 'TRANGE')"]},{"cell_type":"markdown","id":"c8516890-33c7-4d4f-9d71-c6fe8ed896b9","metadata":{},"outputs":[],"source":["\u003cp\u003eAs the TRANGE goes up, the Volume goes up: this indicates a positive direct correlation between these two variables. TRANGE seems like a predictor of Volume since the regression line is almost aligned to the diagonal line.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"93b7482f-b243-43f4-b1a2-afa4e6b5b875","metadata":{},"outputs":[],"source":["We can examine the correlation between them and see it's approximately 0.789.\n"]},{"cell_type":"code","id":"db1a5d32-55f9-4cc6-8db4-915f7e7ea9e9","metadata":{},"outputs":[],"source":["df[[\"Volume\", \"TRANGE\"]].corr()"]},{"cell_type":"markdown","id":"5748fbe9-fad3-4a64-ad73-9cbf8a17ed13","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\n","\u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #2 a):\u003c/b\u003e\n","\n","\u003cp\u003eFind the correlation between \u003cstrong\u003ePrice\u003c/strong\u003e and \u003cstrong\u003eADOSC\u003c/strong\u003e.\u003c/p\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"2896b29e-8ba7-4c7b-9b91-d2d3e16fa239","metadata":{},"outputs":[],"source":["\u003cstrong\u003e\u003cem\u003eNote:\u003c/em\u003e\u003c/strong\u003e if you would like to select those columns, use the following syntax: \u003ccode\u003edf[['Price','ADOSC']]\u003c/code\u003e.\n"]},{"cell_type":"code","id":"9f1c7abd-7778-4da0-a711-d0236c60e5b2","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute\n\n# find the correlation\ndf[[\"Price\", \"ADOSC\"]].corr()"]},{"cell_type":"markdown","id":"cbf0e47e-f8d7-42d6-8b4c-a750a6a53bd5","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","# find the correlation\n","df[[\"Price\", \"ADOSC\"]].corr()\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"4e7ae2e0-a140-496f-8a0f-c4031bb86dda","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #2 b):\u003c/b\u003e\n","\n","\u003cp\u003eGiven the correlation results between \u003cstrong\u003ePrice\u003c/strong\u003e and \u003cstrong\u003eADOSC\u003c/strong\u003e, do you expect a linear relationship?\u003c/p\u003e \n","\u003cp\u003eVerify your results using the function \u003ccode\u003eregplot()\u003c/code\u003e.\u003c/p\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"584839b4-165b-4f32-9861-63b00400fae2","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n\nregplot(df, 'Price', 'ADOSC')"]},{"cell_type":"markdown","id":"68d74b53-eb43-476e-ad88-0159fbc38484","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","\n","#There is a weak correlation between the variables. As such regression will not work well. We can see this using \"regplot\" to demonstrate this.\n","\n","#Code: \n","regplot(df, 'Price', 'ADOSC')\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"b421d6f9-e4cd-4f99-90f8-7ff04ede8476","metadata":{},"outputs":[],"source":["There is a weak correlation between the variables Price and ADOSC. As such regression will not work well.\n"]},{"cell_type":"markdown","id":"b77407ea-4b57-4af5-a133-85e8c767b9f1","metadata":{},"outputs":[],"source":["### Categorical Variables\n","\n","\u003cp\u003e\u003cstrong\u003eCategorical variables\u003c/strong\u003e are variables that describe a 'characteristic' of a data unit, and are selected from a small group of categories. The categorical variables can have the type \u003ccode\u003eobject\u003c/code\u003e or \u003ccode\u003eint64\u003c/code\u003e. A good way to visualize categorical variables is by using \u003cstrong\u003eboxplots.\u003c/strong\u003e\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"5a5048a3-dcec-4fb2-9103-afc479d04e14","metadata":{},"outputs":[],"source":["Let's create the following categorical values: \n"]},{"cell_type":"code","id":"e2ebafed-9f7e-47e9-a01f-b1e1a31ba328","metadata":{},"outputs":[],"source":["group_names = [\"Low\", \"Medium\", \"High\"]"]},{"cell_type":"markdown","id":"1d228f98-b02b-49d6-a840-b845d9251a45","metadata":{},"outputs":[],"source":["Similiar to previous module, declare a function to create categorical variables for a given dataframe column.  \n"]},{"cell_type":"code","id":"3b85afee-08a3-431f-9e6e-973973d0f0cd","metadata":{},"outputs":[],"source":["def to_categorical(column: pd.Series, categories: List[str]) -\u003e pd.Series:\n    \"\"\" Return categorical variables for a given dataframe column.\n    \"\"\"\n    bins = np.linspace(min(column), max(column), len(categories) + 1)\n    return pd.cut(column, bins, labels=categories, include_lowest=True)"]},{"cell_type":"markdown","id":"6545d70e-54a6-40db-a6ff-a4c593ead61d","metadata":{},"outputs":[],"source":["Let's use declared function on BTCBUSD price.\n"]},{"cell_type":"code","id":"e583749a-9b00-4370-868f-5b6979fc34ea","metadata":{},"outputs":[],"source":["df['Price_binned'] = to_categorical(df['Price'], group_names)\ndf[['Price', 'Price_binned']].head()"]},{"cell_type":"code","id":"2e16c37a-c6ed-4ab7-b4b6-e187ce50efc7","metadata":{},"outputs":[],"source":["df['Price_binned'].value_counts()"]},{"cell_type":"markdown","id":"e4845c78-02e5-4027-b372-67d1a5a6d7fc","metadata":{},"outputs":[],"source":["Great! Now we are one step closer to fully understand our dataset.\n"]},{"cell_type":"markdown","id":"96aeb77c-6f65-4884-9b5b-f21255f00d8e","metadata":{},"outputs":[],"source":["#### Visualization of categorical variables\n"]},{"cell_type":"markdown","id":"6a43336b-151d-4ba0-ba3a-caedfaa65e39","metadata":{},"outputs":[],"source":["#### What is  a boxplot?\n","\n","\u003cstrong\u003e\u003cem\u003eA boxplot\u003c/em\u003e\u003c/strong\u003e is a graph that gives you a good indication of how the values in the data are spread out. We use a boxplot below to analyze the relationship between a categorical feature and a continuous feature.\n"]},{"cell_type":"markdown","id":"92a260de-01d4-4e69-aa2c-a440424d660d","metadata":{},"outputs":[],"source":["Let's look at the relationship between \u003cstrong\u003e\"BTCBUSD_Price\"\u003c/strong\u003e and \u003cstrong\u003e\"BTCBUSD_Price_binned\"\u003c/strong\u003e. \n"]},{"cell_type":"code","id":"b678aaee-17ba-40fe-a29f-6293d03bd87b","metadata":{},"outputs":[],"source":["sns.boxplot(x='Price', y='Price_binned', data=df)"]},{"cell_type":"markdown","id":"17bb8b59-1839-4e87-84a1-2e5ec82234e2","metadata":{},"outputs":[],"source":["Here we see that the distribution of price between these three categories are distinct enough to take in which catagery price will be.\n"]},{"cell_type":"markdown","id":"f92fdda6-5332-4776-a1c4-7adabc9f7ee7","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #3:\u003c/b\u003e\n","\n","\u003cp\u003eCreate the same categories for \u003cstrong\u003eVolume\u003c/strong\u003e and \u003cstrong\u003eindicators ADOSC, NATR, TRANGE.\u003c/strong\u003e\u003c/p\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"markdown","id":"2043785d-154b-41f2-8d66-286b5a1af221","metadata":{},"outputs":[],"source":["\u003cstrong\u003e\u003cem\u003eNote:\u003c/em\u003e\u003c/strong\u003e use declared \u003ccode\u003eto_categorical()\u003c/code\u003e function.\u003c/p\u003e\n"]},{"cell_type":"code","id":"e3153392-7394-4d20-ae6a-32e8a4730eaa","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute\n\n# create categories for currencies price\nindicators = ['Volume', 'ADOSC', 'NATR', 'TRANGE']\nfor indicator in indicators:\n    df[f'{indicator}_binned'] = to_categorical(df[indicator], group_names)\n\n# filter display categorical columns\ndf.filter(regex='_binned').head()"]},{"cell_type":"markdown","id":"2c48cefa-ea44-48b9-a6bd-c52330e03271","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python \n","# create categories for currencies price\n","indicators = ['Volume', 'ADOSC', 'NATR', 'TRANGE']\n","for indicator in indicators:\n","    df[f'{indicator}_binned'] = to_categorical(df[indicator], group_names)\n","\n","# filter display categorical columns\n","df.filter(regex='_binned').head()\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"9f197e8a-109f-4cf0-a692-0634be197cc1","metadata":{},"outputs":[],"source":["## 3. Descriptive Statistical Analysis\n"]},{"cell_type":"markdown","id":"b59561ac-c532-4866-9f77-7d3fc85c8cea","metadata":{},"outputs":[],"source":["\u003cp\u003eLet's first take a look at the variables by utilizing a description method.\u003c/p\u003e\n","\n","\u003cp\u003eThe \u003cb\u003edescribe\u003c/b\u003e function automatically computes basic statistics for all continuous variables. Any NaN values are automatically skipped in these statistics.\u003c/p\u003e\n","\n","This will show:\n","\n","\u003cul\u003e\n","    \u003cli\u003ethe count of that variable\u003c/li\u003e\n","    \u003cli\u003ethe mean\u003c/li\u003e\n","    \u003cli\u003ethe standard deviation (std)\u003c/li\u003e \n","    \u003cli\u003ethe minimum value\u003c/li\u003e\n","    \u003cli\u003ethe IQR (Interquartile Range: 25%, 50% and 75%)\u003c/li\u003e\n","    \u003cli\u003ethe maximum value\u003c/li\u003e\n","\u003cul\u003e\n"]},{"cell_type":"markdown","id":"7f923875-e838-4779-bb66-d7d62bca33ab","metadata":{},"outputs":[],"source":["We can apply the method \"describe\" as follows:\n"]},{"cell_type":"code","id":"8bcc4db5-35a0-4c5b-ab33-c784fe055150","metadata":{},"outputs":[],"source":["df.describe()"]},{"cell_type":"markdown","id":"420bfb2e-1fec-4594-be5a-09ce050768a5","metadata":{},"outputs":[],"source":["The default setting of \"describe\" skips variables of type object. We can apply the method \"describe\" on the variables of type 'object' as follows:\n"]},{"cell_type":"code","id":"8682854c-8da6-4d03-a396-dbc49d63d295","metadata":{},"outputs":[],"source":["df.describe(include=['category'])"]},{"cell_type":"markdown","id":"a7923fb8-4d5e-4bb3-a161-52787ea026ea","metadata":{},"outputs":[],"source":["#### Value Counts\n"]},{"cell_type":"markdown","id":"5054dc32-81e4-43cf-b0a5-cacd0a8656a9","metadata":{},"outputs":[],"source":["\u003cp\u003e\u003cstrong\u003eValue counts\u003c/strong\u003e is a good way of understanding how many units of each characteristic/variable we have. We can apply the \u003ccode\u003evalue_counts()\u003c/code\u003e method on the column \u003cstrong\u003e\"BTCBUSD_Price_binned\"\u003c/strong\u003e. Don’t forget the method \u003ccode\u003evalue_counts()\u003c/code\u003e only works on pandas series, not pandas dataframes. As a result, we only include one bracket \u003ccode\u003edf['BTCBUSD_Price_binned']\u003c/code\u003e, not two brackets \u003ccode\u003edf[['BTCBUSD_Price_binned']]\u003c/code\u003e.\u003c/p\u003e\n"]},{"cell_type":"code","id":"42b4f5b8-7eb1-4c55-9fcc-9e3c9ab57eda","metadata":{},"outputs":[],"source":["df['Price_binned'].value_counts()"]},{"cell_type":"markdown","id":"c9ae3133-eab7-4fc6-8cb4-956ca2f2041c","metadata":{},"outputs":[],"source":["We can convert the series to a dataframe as follows:\n"]},{"cell_type":"code","id":"129d5dc6-c5c4-40a1-ab48-da5bb755f5c3","metadata":{},"outputs":[],"source":["df['Price_binned'].value_counts().to_frame()"]},{"cell_type":"markdown","id":"d65da0c9-1e0d-4daf-8ed1-923a3d08dc43","metadata":{},"outputs":[],"source":["Let's repeat the above steps but save the results to the dataframe \u003cstrong\u003e\"BTCBUSD_Price_binned_counts\"\u003c/strong\u003e and rename the column \u003cstrong\u003e\"BTCBUSD_Price_binned\"\u003c/strong\u003e to \u003cstrong\u003e\"value_counts\"\u003c/strong\u003e.\n"]},{"cell_type":"code","id":"0a693f59-610e-4708-a0d4-c4b687e6f190","metadata":{},"outputs":[],"source":["BTCBUSD_Price_binned_counts = df['Price_binned'].value_counts().to_frame()\nBTCBUSD_Price_binned_counts.rename(columns={'Price_binned': 'value_counts'}, inplace=True)\nBTCBUSD_Price_binned_counts"]},{"cell_type":"markdown","id":"73af3fd7-cba6-43e8-9409-365e783d02cc","metadata":{},"outputs":[],"source":["Now let's rename the index to \u003cstrong\u003e\"BTCBUSD_Price_binned\"\u003c/strong\u003e:\n"]},{"cell_type":"code","id":"b8d4ad1e-739d-43eb-9cba-9566f861f8f9","metadata":{},"outputs":[],"source":["BTCBUSD_Price_binned_counts.index.name = 'category'\nBTCBUSD_Price_binned_counts"]},{"cell_type":"markdown","id":"e1acd365-b8eb-4273-a9ce-7dc8532662b0","metadata":{},"outputs":[],"source":["Now let's add indicators into this dataframe:\n"]},{"cell_type":"code","id":"19e9a9de-8f90-41ed-9bf5-40dee10c4f6d","metadata":{},"outputs":[],"source":["category_count = BTCBUSD_Price_binned_counts.copy()\ncategory_count.rename(columns = {'value_counts':'BTCBUSD_value_counts'}, inplace = True)\n\nfor indicator in indicators:\n    column_name = f'{indicator}_binned'\n    # count number of values\n    counts = df[column_name].value_counts().to_frame()\n    # add new column to category_count\n    category_count[f'{indicator}_value_counts'] = counts\n\ncategory_count"]},{"cell_type":"markdown","id":"fd7e2ab8-50f0-4805-b98b-988dfd6700b8","metadata":{},"outputs":[],"source":["## 4. Basics of Grouping\n"]},{"cell_type":"markdown","id":"1233ca36-c2b7-4cd4-8552-b015ab82f076","metadata":{},"outputs":[],"source":["\u003cp\u003eThe \u003ccode\u003egroupby\u003c/code\u003e method groups data by different categories. The data is grouped based on one or several variables, and analysis is performed on the individual groups.\u003c/p\u003e\n","\n","\u003cp\u003eFor example, let's group by the variable \u003cstrong\u003e\"BTCBUSD_Price\"\u003c/strong\u003e. We see that there are 5 different categories of price.\u003c/p\u003e\n"]},{"cell_type":"code","id":"ea902cb1-acff-49e6-bbf0-6f6fa62d80bd","metadata":{},"outputs":[],"source":["df['Price_binned'].unique()"]},{"cell_type":"markdown","id":"10ba857e-b343-4205-8b4c-cae5da499b3c","metadata":{},"outputs":[],"source":["\u003cp\u003eIf we want to know, on average, which type of \u003cstrong\u003e\"BTCBUSD_Price\"\u003c/strong\u003e is most valuable, we can group \u003cstrong\u003e\"BTCBUSD_Price\"\u003c/strong\u003e and then average them.\u003c/p\u003e\n","\n","\u003cp\u003eWe can select the columns \u003ccode\u003e'BTCBUSD_Price_binned'\u003c/code\u003e, \u003ccode\u003e'BTCBUSD_Price'\u003c/code\u003e then assign it to the variable \u003cstrong\u003e\"df_group_one\".\u003c/strong\u003e\u003c/p\u003e\n"]},{"cell_type":"code","id":"f787c1cd-4999-4175-96a7-1b8d60f3f9d3","metadata":{},"outputs":[],"source":["df_group_one = df[['Price_binned', 'Price']]"]},{"cell_type":"markdown","id":"e9e44b36-1e1e-40d9-af85-38d2fd4d7b77","metadata":{},"outputs":[],"source":["We can then calculate the price for each of the different categories of data.\n"]},{"cell_type":"code","id":"1615e38b-b587-4dfd-a793-bdec316f2831","metadata":{},"outputs":[],"source":["# grouping results\ndf_group_one = df_group_one.groupby(['Price_binned'], as_index=True).mean()\ndf_group_one"]},{"cell_type":"markdown","id":"36d79cba-ea54-4e8d-b40f-75ecbc18c76f","metadata":{},"outputs":[],"source":["\u003cp\u003eFrom our data, it more than predictable that \u003cstrong\u003e'High'\u003c/strong\u003e category has the highest price value.\u003c/p\u003e\n","\n","\u003cp\u003eYou can also group by multiple variables. For example, let's group by both \u003ccode\u003e'BTCBUSD_Price_binned'\u003c/code\u003e and \u003ccode\u003e'ADOSC_Price_binned'\u003c/code\u003e. This groups the dataframe by the unique combination of \u003ccode\u003e'BTCBUSD_Price_binned'\u003c/code\u003e and \u003ccode\u003e'ADOSC_Price_binned'\u003c/code\u003e. We can store the results in the variable \u003ccode\u003e'grouped_test_1'\u003c/code\u003e.\u003c/p\u003e\n"]},{"cell_type":"code","id":"869c419a-2827-4854-8d6e-fc6fda1f9978","metadata":{},"outputs":[],"source":["# grouping results\ndf_gptest = df[['Price_binned','ADOSC_binned','Price']]\ngrouped_test1 = df_gptest.groupby(['Price_binned','ADOSC_binned'],as_index=False).mean()\ngrouped_test1"]},{"cell_type":"markdown","id":"20f3be94-098d-44a6-85a2-7fbc99e65aa9","metadata":{},"outputs":[],"source":["This grouped data is much easier to visualize when it is made into a \u003cstrong\u003epivot table\u003c/strong\u003e. \n","\n","#### What is a pivot table?\n","A pivot table is like an Excel spreadsheet, with one variable along the column and another along the row. We can convert the dataframe to a pivot table using the method \u003ccode\u003epivot\u003c/code\u003e to create a pivot table from the groups.\n","\n","\u003cp\u003eIn this case, we will leave the \u003cstrong\u003e'BTCBUSD_Price_binned'\u003c/strong\u003e variable as the rows of the table, and pivot \u003cstrong\u003e'ADABUSD_Price_binned'\u003c/strong\u003e to become the columns of the table:\u003c/p\u003e\n"]},{"cell_type":"code","id":"3db62dd0-a3cd-4d0f-83b5-0e354532b7e5","metadata":{},"outputs":[],"source":["grouped_pivot = grouped_test1.pivot(index='Price_binned',columns='ADOSC_binned')\ngrouped_pivot"]},{"cell_type":"markdown","id":"a6a0b096-52d4-4feb-ac5d-50de5ac028be","metadata":{},"outputs":[],"source":["Often, we won't have data for some of the pivot cells. We can fill these missing cells with the value 0 by \u003ccode\u003e.fillna(0)\u003c/code\u003e, but any other value could potentially be used as well. It should be mentioned that missing data is quite a complex subject and is an entire course on its own.\n"]},{"cell_type":"markdown","id":"2cd212d1-5b51-464e-af96-a57c24ab8342","metadata":{},"outputs":[],"source":["Also we can use a crossed table to see how many values correspond to each other in the table.\n"]},{"cell_type":"code","id":"514cb246-6c0c-4103-8ff6-66f900ed96e0","metadata":{},"outputs":[],"source":["crossed_table = pd.crosstab(df['Price_binned'], df['ADOSC_binned'])\ncrossed_table"]},{"cell_type":"markdown","id":"a60ffa5e-0d77-4202-88dc-b703477ae4f4","metadata":{},"outputs":[],"source":["From that we can suggest that ADOSC indicator medium binned values is pretty good distributed for Price binned.  \n"]},{"cell_type":"markdown","id":"4348d4c1-539f-4da4-a7ec-4ecd56731765","metadata":{},"outputs":[],"source":["\u003cdiv class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\"\u003e\n","\u003cb style=\"font-size: 2em; font-weight: 600;\"\u003eQuestion #4:\u003c/b\u003e\n","\n","\u003cp\u003eUse the \u003ccode\u003egroupby()\u003c/code\u003e function to find \u003cstrong\u003ethe average TRANGE value\u003c/strong\u003e of each category based on the \u003cstrong\u003e'TRANGE_binned'\u003c/strong\u003e.\u003c/p\u003e\n","\u003c/div\u003e\n"]},{"cell_type":"code","id":"b3e4c380-c8a4-4893-9321-6a0e8e5cd570","metadata":{},"outputs":[],"source":["# Write your code below and press Shift+Enter to execute \n\n# grouping results\ndf_gptest2 = df[['TRANGE_binned','TRANGE']]\ngrouped_test_bodystyle = df_gptest2.groupby(['TRANGE_binned'],as_index=True).mean()\ngrouped_test_bodystyle"]},{"cell_type":"markdown","id":"2761266b-20ab-4936-bcfc-f5ae3b684962","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\u003csummary\u003eClick here for the solution\u003c/summary\u003e\n","\n","```python\n","\n","# grouping results\n","df_gptest2 = df[['TRANGE_binned','TRANGE']]\n","grouped_test_bodystyle = df_gptest2.groupby(['TRANGE_binned'],as_index=True).mean()\n","grouped_test_bodystyle\n","\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","id":"d86855d0-4c86-40e7-b3eb-10f248cbb077","metadata":{},"outputs":[],"source":["Well done! Let's move to visualization. \n"]},{"cell_type":"markdown","id":"d4f2fa33-3e46-4426-b613-3e23368c87d5","metadata":{},"outputs":[],"source":["### Visualization of relationships \n"]},{"cell_type":"markdown","id":"26834067-9e88-48cc-a945-798c7060a05c","metadata":{},"outputs":[],"source":["Visualization methods show relationships and connections between the data or show correlations between two or more variables.\n","\n","Execute the following to adjust astropy.\n"]},{"cell_type":"code","id":"84fb1d31-f9fb-4b7d-84d4-32877610ae79","metadata":{},"outputs":[],"source":["astropy_mpl_style['axes.grid'] = False\nplt.style.use(astropy_mpl_style)"]},{"cell_type":"markdown","id":"ea184344-ab20-4fe4-88d4-e77618dc3dd7","metadata":{},"outputs":[],"source":["Let's use a heat map to visualize the relationship between \u003cstrong\u003eBTCBUSD_Price_binned\u003c/strong\u003e \u003cem\u003evs.\u003c/em\u003e \u003cstrong\u003eADOSC_binned\u003c/strong\u003e.\n"]},{"cell_type":"code","id":"c962f18d-f296-45e2-a955-b86fd9ee443e","metadata":{},"outputs":[],"source":["#use the grouped results\nplt.pcolor(crossed_table, cmap='RdBu')\nplt.colorbar()\nplt.show()"]},{"cell_type":"markdown","id":"e05e9ef9-3c91-472d-8fbb-5a46c8d55ae5","metadata":{},"outputs":[],"source":["\u003cp\u003eThe heatmap plots the target variable \u003cem\u003e(price)\u003c/em\u003e proportional to colour with respect to the variables \u003cstrong\u003e'Price_binned'\u003c/strong\u003e and \u003cstrong\u003e'ADOSC_binned'\u003c/strong\u003e on the vertical and horizontal axis, respectively. This allows us to visualize how the price is related to \u003cstrong\u003e'Price_binned'\u003c/strong\u003e and \u003cstrong\u003e'ADOSC_binned.\u003c/strong\u003e\u003c/p\u003e\n","\n","\u003cp\u003eThe default labels convey no useful information to us. Let's change that:\u003c/p\u003e\n"]},{"cell_type":"code","id":"b6ee22fe-c77d-4177-9e02-73c6775f9b1d","metadata":{},"outputs":[],"source":["fig, ax = plt.subplots()\nim = ax.pcolor(crossed_table, cmap='RdBu')\n\n#label names\nrow_lables = crossed_table.columns.categories\ncol_labels = crossed_table.index\n\n#move ticks and labels to the center\nax.set_xticks(np.arange(crossed_table.shape[1]) + 0.5, minor=False)\nax.set_yticks(np.arange(crossed_table.shape[0]) + 0.5, minor=False)\n\n#insert labels\nax.set_xticklabels(col_labels, minor=False)\nax.set_yticklabels(row_lables, minor=False)\n\nplt.xlabel(\"ADOSC\")\nplt.ylabel(\"BTCBUSD\")\n\n#rotate label if too long\nplt.xticks(rotation=90)\n\nfig.colorbar(im, label='Count')\nplt.show()"]},{"cell_type":"markdown","id":"d8cd61e8-25a4-4b0c-8fd9-7243429ed25d","metadata":{},"outputs":[],"source":["Now we can see more precisely how ADOSC medium binned value are distributed over BTCBUSD price categories. Even though, it cannot be said about other ADOSC bins.\n"]},{"cell_type":"markdown","id":"a61dd10f-9fcf-4449-b8a2-c4234c6f9d73","metadata":{},"outputs":[],"source":["\u003cp\u003eVisualization is very important in data science, and Python visualization packages provide great freedom. We will go more in-depth in a separate Python visualizations course.\u003c/p\u003e\n","\n","\u003cp\u003eThe main question we want to answer in this module is \u003cstrong\u003e\u003cem\u003e\"What are the main characteristics that have the most impact on the price of cryptocurrency?\"\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n","\n","\u003cp\u003eTo get a better measure of the important characteristics, we look at the correlation of our currency with indicators and other cryptocurrencies. In other words: \u003cstrong\u003e\u003cem\u003ehow is the price dependent on other variables?\u003c/em\u003e\u003c/strong\u003e\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"b36f4f4e-b3f4-45f7-9f3a-a709382043c9","metadata":{},"outputs":[],"source":["## 5. Correlation and Causation\n"]},{"cell_type":"markdown","id":"88e2c9ca-7877-4001-b093-affdabecb269","metadata":{},"outputs":[],"source":["#### What is correlation and causation?\n","\n","\u003cstrong\u003eCorrelation\u003c/strong\u003e: a measure of the extent of interdependence between variables.\n","\n","\u003cstrong\u003eCausation\u003c/strong\u003e: the relationship between cause and effect between two variables.\n","\n","\u003cem\u003e\u003cstrong\u003eIt is important to know the difference between these two\u003c/strong\u003e\u003c/em\u003e.\n","\n","\u003cli\u003eCorrelation does not imply causation.\u003c/li\u003e\n","\u003cli\u003eDetermining correlation is much simpler than the determining causation as causation may require independent experimentation.\u003c/li\u003e\n"]},{"cell_type":"markdown","id":"ceeb1a76-3de5-4d14-9814-4498d0ad3e1c","metadata":{},"outputs":[],"source":["#### Pearson Correlation\n","\u003cp\u003e\u003cstrong\u003e\u003cem\u003eThe Pearson Correlation\u003c/em\u003e\u003c/strong\u003e measures the linear dependence between two variables X and Y. In addition, It estimates the relationship strength between the two continuous variables.\u003c/p\u003e\n","\u003cp\u003eThe resulting coefficient is a value between \u003cstrong\u003e-1\u003c/strong\u003e and \u003cstrong\u003e1\u003c/strong\u003e inclusive, where:\u003c/p\u003e\n","\u003cul\u003e\n","    \u003cli\u003e\u003cstrong\u003e1\u003c/strong\u003e: Perfect positive linear correlation.\u003c/li\u003e\n","    \u003cli\u003e\u003cstrong\u003e0\u003c/strong\u003e: No linear correlation, the two variables most likely do not affect each other.\u003c/li\u003e\n","    \u003cli\u003e\u003cstrong\u003e-1\u003c/strong\u003e: Perfect negative linear correlation.\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","The formula for Perason Correaltion between X and Y is represented as:\n","\n","$$\n","r = \\frac{n \\sum \\limits _{i=1} ^{n} xy - \\sum \\limits _{i=1} ^{n} x \\sum \\limits _{i=1} ^{n} y}{\\sqrt{[n \\sum \\limits _{i=1} ^{n} x^2 - (\\sum \\limits _{i=1} ^{n} x)^2][n \\sum \\limits _{i=1} ^{n} y^2 - (\\sum \\limits _{i=1} ^{n} y)^2]}}\n","$$\n"]},{"cell_type":"markdown","id":"21b0b3f1-53db-4d32-ab55-9eac0ec59522","metadata":{},"outputs":[],"source":["\u003cp\u003ePearson Correlation is the default method of the function \u003ccode\u003ecorr()\u003c/code\u003e. Like before, we can calculate the Pearson Correlation of the \u003ccode\u003eint64\u003c/code\u003e or \u003ccode\u003e'float64'\u003c/code\u003e variables.\u003c/p\u003e\n"]},{"cell_type":"code","id":"67824510-1087-4c29-a7c2-4785307e590a","metadata":{},"outputs":[],"source":["df.corr()"]},{"cell_type":"markdown","id":"d48a499b-26c8-4555-aaea-2654ba1acc43","metadata":{},"outputs":[],"source":["Sometimes we would like to know the significant of the correlation estimate.\n"]},{"cell_type":"markdown","id":"2208b310-ecbe-4792-bd60-0784e2e4835c","metadata":{},"outputs":[],"source":["#### P-value\u003c/strong\u003e\n","\n","\u003cstrong\u003eWhat is this P-value?\u003c/strong\u003e \n","\n","\u003cem\u003e\u003cstrong\u003eThe P-value\u003c/strong\u003e\u003c/em\u003e is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.\n","\n","By convention, when\n","\n","\u003cul\u003e\n","    \u003cli\u003e\u003cem\u003ethe p-value\u003c/em\u003e is $\u003c$ \u003cstrong\u003e0.001\u003c/strong\u003e: we say there is strong evidence that the correlation is significant.\u003c/li\u003e\n","    \u003cli\u003e\u003cem\u003ethe p-value\u003c/em\u003e is $\u003c$ \u003cstrong\u003e0.05\u003c/strong\u003e: there is moderate evidence that the correlation is significant.\u003c/li\u003e\n","    \u003cli\u003e\u003cem\u003ethe p-value\u003c/em\u003e is $\u003c$ \u003cstrong\u003e0.1\u003c/strong\u003e: there is weak evidence that the correlation is significant.\u003c/li\u003e\n","    \u003cli\u003e\u003cem\u003ethe p-value\u003c/em\u003e is $\u003e$ \u003cstrong\u003e0.1\u003c/strong\u003e: there is no evidence that the correlation is significant.\u003c/li\u003e\n","\u003c/ul\u003e\n"]},{"cell_type":"markdown","id":"d9be07ce-bebc-4289-9be1-5733f4a08172","metadata":{},"outputs":[],"source":["Let's calculate the  Pearson Correlation Coefficient and P-value of our currency price and indicators.\n"]},{"cell_type":"code","id":"93340486-2f0d-4cc2-91d5-8af7ad71014b","metadata":{},"outputs":[],"source":["df_stats = pd.DataFrame({\"indicator\":[], \"pearson\": [], \"p-value\": []})\npd.options.display.float_format = '{:.3f}'.format\n\nfor indicator in indicators:\n    pearson_coef, p_value = stats.pearsonr(df['Price'], df[indicator])\n    df_stats.loc[len(df_stats.index)] = [indicator, pearson_coef, p_value]\n\ndf_stats.set_index('indicator', inplace=True)\ndf_stats"]},{"cell_type":"markdown","id":"191160e0-e31c-46fd-8506-d4fe0acd9798","metadata":{},"outputs":[],"source":["#### Conclusion:\n","\u003cp\u003eSince the \u003cstrong\u003e\u003cem\u003ep-value is $\u003c$ 0.001\u003c/em\u003e\u003c/strong\u003e, the correlation between our currency price and the others parameters is statistically significant, although the linear relationship isn't strong as the correlation values are too small and approach zero.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"19bd2207-c679-4d44-b47b-b18e79224419","metadata":{},"outputs":[],"source":["## 6. ANOVA\n"]},{"cell_type":"markdown","id":"d76a1dd5-0875-4aac-ba3e-55c22c5483b4","metadata":{},"outputs":[],"source":["### Analysis of Variance (ANOVA)\n","\u003cp\u003e\u003cstrong\u003eThe Analysis of Variance (ANOVA)\u003c/strong\u003e is a statistical method used to test whether there are significant differences between the means of two or more groups.\u003c/p\u003e\n","    \n","ANOVA returns two parameters: \u003cstrong\u003e\u003cem\u003eF-test score\u003c/em\u003e\u003c/strong\u003e and \u003cstrong\u003e\u003cem\u003eP-value\u003c/em\u003e\u003c/strong\u003e.\n","\n","\u003cp\u003e\u003cstrong\u003eF-test score\u003c/strong\u003e: ANOVA assumes the means of all groups are the same, calculates how much the actual means deviate from the assumption, and reports it as the F-test score. A larger score means there is a larger difference between the means.\u003c/p\u003e\n","\u003cp\u003e\u003cstrong\u003eP-value\u003c/strong\u003e:  P-value tells how statistically significant our calculated score value is.\u003c/p\u003e\n","\n","\u003cp\u003eIf our price variable is strongly correlated with the variable we are analyzing, we expect ANOVA to return a \u003cstrong\u003e\u003cem\u003esizeable F-test score\u003c/em\u003e\u003c/strong\u003e and a \u003cstrong\u003e\u003cem\u003esmall p-value\u003c/em\u003e\u003c/strong\u003e.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"5e5a84c1-5268-4715-b671-29f5f9e62667","metadata":{},"outputs":[],"source":["### Category\n"]},{"cell_type":"markdown","id":"f957c283-ccd5-4e82-bdf9-69a15be58546","metadata":{},"outputs":[],"source":["\u003cp\u003eSince ANOVA analyzes the difference between different groups of the same variable, the groupby function will come in handy. Because the ANOVA algorithm averages the data automatically, we do not need to take the average before hand.\u003c/p\u003e\n","\n","\u003cp\u003eTo see if different types of \u003cstrong\u003e'BTCBUSD_Price_binned'\u003c/strong\u003e impact \u003cstrong\u003e'BTCBUSD_Price'\u003c/strong\u003e, we group the data.\u003c/p\u003e\n"]},{"cell_type":"code","id":"f5075780-c2f3-43f3-8075-b2abbbcd0da8","metadata":{},"outputs":[],"source":["grouped_test2 = df[['Price', 'Price_binned']].groupby(['Price_binned'])\ngrouped_test2.head(2)"]},{"cell_type":"markdown","id":"6f278678-3b80-4b3f-a715-f871debf7cb0","metadata":{},"outputs":[],"source":["We can obtain the values of the method group using the method \u003ccode\u003eget_group()\u003c/code\u003e.\n"]},{"cell_type":"code","id":"5ec19dc5-1f9d-4a7f-b46e-bad4c008ec87","metadata":{},"outputs":[],"source":["grouped_test2.get_group('Medium')['Price'].to_frame()"]},{"cell_type":"markdown","id":"ae15c480-42b5-4f95-8149-ab253b0082fb","metadata":{},"outputs":[],"source":["We can use the function \u003ccode\u003ef_oneway\u003c/code\u003e in the module \u003cstrong\u003e'stats'\u003c/strong\u003e to obtain the \u003cstrong\u003eF-test score\u003c/strong\u003e and \u003cstrong\u003eP-value\u003c/strong\u003e.\n"]},{"cell_type":"code","id":"213d2142-3910-4f47-9912-b52cbf6f0fe7","metadata":{},"outputs":[],"source":["# ANOVA\nf_val, p_val = stats.f_oneway(grouped_test2.get_group('Low')['Price'],\n                              grouped_test2.get_group('Medium')['Price'],\n                              grouped_test2.get_group('High')['Price'])\n\nprint( \"ANOVA results: F=\", f_val, \", P =\", p_val)"]},{"cell_type":"markdown","id":"00221adc-6274-4abd-acce-e7f773e4a78e","metadata":{},"outputs":[],"source":["This is a great result with a large F-test score showing a strong correlation and a P-value of 0 implying almost certain statistical significance. But does this mean all these groups are all this highly correlated?\n"]},{"cell_type":"markdown","id":"1a446f9a-f8c6-4b9d-82eb-4a46506f2520","metadata":{},"outputs":[],"source":["#### ANOVA for different category combinations\n"]},{"cell_type":"code","id":"68e1eff9-f68a-4880-a2cf-b58d6162ff15","metadata":{},"outputs":[],"source":["df_ANOVA = pd.DataFrame({\"Price categories\":[], \"f-score\": [], \"p-value\": []})\n\ncombinator = list(itertools.combinations(group_names, 2))\nfor first, second in combinator:\n    f_val, p_val = stats.f_oneway(grouped_test2.get_group(first)['Price'], \n                                  grouped_test2.get_group(second)['Price'])\n    df_ANOVA.loc[len(df_ANOVA.index)] = [f'{first} and {second}', f_val, p_val]\n\ndf_ANOVA.set_index('Price categories', inplace=True)\ndf_ANOVA"]},{"cell_type":"markdown","id":"340121de-4175-48a5-94d5-3b714093abca","metadata":{},"outputs":[],"source":["As you can see a great result with a large F-test score showing a strong correlation and a P-value of 0 implying certain statistical significance is obtained. This means all these groups are all highly correlated.\n"]},{"cell_type":"markdown","id":"c1586bed-b56f-4408-aad0-7689199f7da1","metadata":{},"outputs":[],"source":["### ANOVA for indicators\n"]},{"cell_type":"markdown","id":"193ba718-011d-4e63-98f6-b5290b31e013","metadata":{},"outputs":[],"source":["Let's check how strong each of indicators groups are correlated.\n"]},{"cell_type":"code","id":"dfcbbaa8-1404-4b92-9cea-e9df4f14c1d4","metadata":{},"outputs":[],"source":["for indicator in indicators:\n    grouped_test_indicator = df[[indicator, f'{indicator}_binned']].groupby([f'{indicator}_binned'])\n\n    df_ANOVA = pd.DataFrame({f'{indicator} categories':[], 'f-score': [], 'p-value': []})\n\n    # ANOVA\n    f_val, p_val = stats.f_oneway(grouped_test_indicator.get_group('Low')[indicator],\n                                  grouped_test_indicator.get_group('Medium')[indicator],\n                                  grouped_test_indicator.get_group('High')[indicator])\n    df_ANOVA.loc[len(df_ANOVA.index)] = ['High, Medium and Low', f_val, p_val]\n\n    combinator = list(itertools.combinations(group_names, 2))\n    for first, second in combinator:\n        f_val, p_val = stats.f_oneway(grouped_test_indicator.get_group(first)[f'{indicator}'], \n                                      grouped_test_indicator.get_group(second)[f'{indicator}'])\n        df_ANOVA.loc[len(df_ANOVA.index)] = [f'{first} and {second}', f_val, p_val]\n\n    df_ANOVA.set_index(f'{indicator} categories', inplace=True)\n    display(df_ANOVA)\n    print()"]},{"cell_type":"markdown","id":"f98ea08c-f6ad-4fa0-9428-0dec799ade2d","metadata":{},"outputs":[],"source":["We can see how the Volume parameter has the most correlated groups of categories, while other indicators show slightly lower values. However, every P-value is close to 0 implying certain statistical significance is obtained.\n"]},{"cell_type":"markdown","id":"1b6906a5-928a-40d6-8ee0-9d741e344afc","metadata":{},"outputs":[],"source":["## 7. Durbin Watson Test\n"]},{"cell_type":"markdown","id":"b676c1c7-0d50-4a55-b188-0068cd64026d","metadata":{},"outputs":[],"source":["#### What Is the Durbin Watson Statistic?\n","\n","\u003cstrong\u003eThe Durbin Watson (DW) statistic\u003c/strong\u003e is a test for autocorrelation in the residuals from a statistical model or regression analysis. The Durbin-Watson statistic will always have \u003cem\u003ea value ranging between 0 and 4\u003c/em\u003e.\n","\n","\u003cli\u003e\u003cstrong\u003ea value of 2.0\u003c/strong\u003e indicates there is no autocorrelation detected in the sample.\u003c/li\u003e \n","\u003cli\u003e\u003cstrong\u003evalues from 0 to less than 2\u003c/strong\u003e point to positive autocorrelation\u003c/li\u003e\n","\u003cli\u003e\u003cstrong\u003evalues from 2 to 4\u003c/strong\u003e means negative autocorrelation\u003c/li\u003e\n","\n","\u003cbr\u003e\n","\u003cp\u003e\n","A rule of thumb is that DW test statistic values \u003cem\u003e\u003cstrong\u003e in the range of 1.5 to 2.5 are relatively normal\u003c/strong\u003e\u003c/em\u003e. Values outside this range could, however, be a cause for concern. \n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"a55015fa-ba85-4eb9-a80b-7af624a762dd","metadata":{},"outputs":[],"source":["This test uses the following hypotheses:\n","\u003cli\u003e\u003cstrong\u003e$H_0$ (null hypothesis):\u003c/strong\u003e There is no correlation among the residuals.\u003c/li\u003e\n","\u003cli\u003e\u003cstrong\u003e$H_A$ (alternative hypothesis):\u003c/strong\u003e The residuals are autocorrelated.\u003c/li\u003e\n"]},{"cell_type":"markdown","id":"6d065992-90a2-4ffe-ac72-1f854008609b","metadata":{},"outputs":[],"source":["Let's implement a function that creates regression models:\n"]},{"cell_type":"code","id":"97ac5a0a-43cd-4d7e-850d-c44d49cbee1b","metadata":{},"outputs":[],"source":["def get_reg(x: pd.Series, y: pd.Series):\n    \"\"\" Return regression model.\n    \"\"\"\n    # to get intercept\n    X = sm.add_constant(x)\n    # fit the regression model\n    reg = sm.OLS(y, X).fit()\n    return reg"]},{"cell_type":"markdown","id":"f50f2cab-ce4f-4004-a511-f0c4d3a1d291","metadata":{},"outputs":[],"source":["Now let's test this function and perform Durbin Watson Test.\n"]},{"cell_type":"code","id":"8c0afe2f-2c54-41a8-a3a0-99e39556ee1d","metadata":{},"outputs":[],"source":["# independent\nX = df['NATR']\n# dependent\ny = df['Price']\nreg = get_reg(X, y)"]},{"cell_type":"code","id":"78d1d087-3b00-4eb5-973c-df7a8c5af3e6","metadata":{},"outputs":[],"source":["print('DW test stats:', durbin_watson(resids=np.array(reg.resid)))"]},{"cell_type":"markdown","id":"38a3d42f-50dd-4d99-96f8-3027cb0f1246","metadata":{},"outputs":[],"source":["DW test statistic value is NOT in the range of 1.5 to 2.5. Therefore, the price and NATR are not relatively normal.\n"]},{"cell_type":"markdown","id":"5f74cc10-f04d-4ddb-abd3-1b1ad4846d44","metadata":{},"outputs":[],"source":["Now that we now how to calculate Durbin-Watson we can evaluate it for the main and indicators with other currencies.\n"]},{"cell_type":"code","id":"1403e8b4-bcae-4cbc-81ac-f1fb73d1e90a","metadata":{},"outputs":[],"source":["df_durbin = pd.DataFrame({'indicator':[], 'durbin-watson': []})\n\nfor indicator in indicators:\n    # independent\n    X = df[indicator]\n    # dependent\n    y = df['Price']\n    reg = get_reg(X, y)\n    dw = durbin_watson(resids=np.array(reg.resid))\n    df_durbin.loc[len(df_durbin.index)] = [indicator, dw]\n\ndf_durbin.set_index('indicator', inplace=True)\ndf_durbin"]},{"cell_type":"markdown","id":"46d25853-67d4-4a35-8bdf-011ca184a73e","metadata":{},"outputs":[],"source":["According to the results of other indicators, we observe the same situation. The influence of indicators on the trend of changes in the price of cryptocurrency is not positively revealed.\n"]},{"cell_type":"markdown","id":"e8daa967-f522-49cc-82a9-ec1803bd5569","metadata":{},"outputs":[],"source":["Let's calculate Durbin-Watson for all available indicator pairs.\n"]},{"cell_type":"code","id":"81e95e26-39fd-4c36-9073-6caa00775321","metadata":{},"outputs":[],"source":["variables = ['Price', 'Volume', 'ADOSC', 'NATR', 'TRANGE']\n\ncols = [f\"{variable}_dep\" for variable in variables]\nidxs = [f\"{variable}_ind\" for variable in variables]\n\ndw_df = pd.DataFrame(columns=cols, index=idxs)\n\nfor (curr1, curr2) in itertools.permutations(variables, 2):\n    # independent variable\n    X = df[f\"{curr1}\"]\n    # dependent variable\n    y = df[f\"{curr2}\"]\n    # to get intercept\n    X = sm.add_constant(X)\n    # fit the regression model\n    reg = sm.OLS(y, X).fit()\n    dw = durbin_watson(resids=np.array(reg.resid))\n    dw_df.loc[f\"{curr1}_ind\", f\"{curr2}_dep\"] = dw\n    \ndw_df"]},{"cell_type":"markdown","id":"0de0092e-25fb-4484-a9da-56b3771ca04f","metadata":{},"outputs":[],"source":["Replace NaN values with empty values.\n"]},{"cell_type":"code","id":"903f40f2-2735-4ee0-bccc-fdcc268546fc","metadata":{},"outputs":[],"source":["np.fill_diagonal(dw_df.values, ' ')\ndw_df"]},{"cell_type":"markdown","id":"ab47c2c1-7c52-4995-bac6-bf0993452028","metadata":{},"outputs":[],"source":["#### Conclusion\n"]},{"cell_type":"markdown","id":"c0fcda86-93ec-4650-9824-19dd9b1e2ab1","metadata":{},"outputs":[],"source":["Any value we choose will have a row for the independent value and a column for the dependent value.\n","\n","if we look at the column of the dependent variable Price, we will see that no indicator of independent variables (indicators) is in the range of 1.5-2.5. This tells that the listed indicators cannot be a good prediction for the price of BTCBUSD currency.\n"]},{"cell_type":"markdown","id":"82f29587-610e-4467-84f2-1ae0bcde043b","metadata":{},"outputs":[],"source":["## 8. Granger-Causality Test\n"]},{"cell_type":"markdown","id":"fed9ef47-fdbd-4a0a-aba0-4d5d54cbb04a","metadata":{},"outputs":[],"source":["#### What is Granger-Causality test?\n","\n","\u003cstrong\u003eThe Granger causality test\u003c/strong\u003e is a statistical hypothesis test for determining whether one time series is useful in forecasting another. If the probability value is less than in our case \u003cem\u003eP-value level\u003c/em\u003e, then the hypothesis would be rejected at that level.\n"]},{"cell_type":"markdown","id":"6752a44a-e2a5-49f5-a53f-a27955cb38fb","metadata":{},"outputs":[],"source":["#### What is the difference between correlation and Granger causality?\n","\n","\u003cstrong\u003e\u003cem\u003eCorrelation\u003c/em\u003e\u003c/strong\u003e is a measure of linear dependence between two random variables. So no additional variables are involved in the calculation of the correlation between X and Z, and also, in principle these variables may be just random variables and not time series.\n","\n","\u003cstrong\u003e\u003cem\u003eGranger causality\u003c/em\u003e\u003c/strong\u003e is a concept of marginal predictability. So here the time dimension of the potential relationship between X and Z is important.\n"]},{"cell_type":"markdown","id":"3ab1bc54-6cc4-4eed-914e-d0bb7b80889a","metadata":{},"outputs":[],"source":["#### What is the null hypothesis in Granger Causality test?\n","\n","\u003cstrong\u003eThe null hypothesis ($H_0$)\u003c/strong\u003e for the test is that lagged x-values do not explain the variation in y. In other words, it assumes that $x_t$ doesn't Granger-cause $y_t$. Theoretically, you can run the Granger Test to find out if two variables are related at an instantaneous moment in time.\n"]},{"cell_type":"markdown","id":"22cd4663-44d0-4cc7-a5fe-5c4a8aad06da","metadata":{},"outputs":[],"source":["Let's visualize price trends movements through specific time period for BTCBUSD currency and NATR indicator.\n"]},{"cell_type":"code","id":"bea11e39-7e53-45e5-bfb3-23e87370e7ab","metadata":{},"outputs":[],"source":["x = df.head(9000).index\ny1 = df['Price'].head(9000)\ny2 = df['ADOSC'].head(9000)\n\n# # Plot Line1 (Left Y Axis)\nfig, ax1 = plt.subplots(1,1,figsize=(16,9), dpi= 80)\nax1.plot(x, y1, color='tab:red')\n\n# # Plot Line2 (Right Y Axis)\n# instantiate a second axes that shares the same x-axis\nax2 = ax1.twinx()\nax2.plot(x, y2, color='tab:blue')\n\n# Decorations\n# ax1 (left Y axis)\nax1.set_xlabel('Time', fontsize=20)\nax1.tick_params(axis='x', rotation=0, labelsize=12)\nax1.set_ylabel('Price', color='tab:red', fontsize=20)\nax1.tick_params(axis='y', rotation=0, labelcolor='tab:red' )\nax1.grid(alpha=.4)\n\n# # ax2 (right Y axis)\nax2.set_ylabel('ADOSC', color='tab:blue', fontsize=20)\nax2.tick_params(axis='y', rotation=0, labelsize=12, labelcolor='tab:blue')\nax2.set_title(\"Visualizing Leading Indicator Phenomenon\", fontsize=22)\n\nfig.tight_layout()\nplt.show()"]},{"cell_type":"markdown","id":"c48c33f0-ab58-4c3c-aa2e-60b7db8ce44a","metadata":{},"outputs":[],"source":["Let's import function implementing Granger Causality test from statsmodels module and declare Granger Causality test calculating function.\n"]},{"cell_type":"code","id":"5392b7c7-48b5-4faf-ba37-bdef18cb1698","metadata":{},"outputs":[],"source":["def grangers_causation_matrix(data: pd.DataFrame, maxlag: int, columns: List[str]) -\u003e pd.DataFrame:\n    \"\"\"Check Granger Causality of all possible combinations of the Time series.\n    data      : pandas dataframe containing the time series variables\n    maxlag    : a maximum possible time delay\n    columns   : list containing names of the time series variables.\n    \"\"\"\n    df = pd.DataFrame(np.zeros((len(columns), len(columns))), columns=columns, index=columns)\n    for c in df.columns:\n        for r in df.index:\n            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n            p_values = [round(test_result[i+1][0]['ssr_chi2test'][1],4) for i in range(maxlag)]\n            min_p_value = np.min(p_values)\n            df.loc[r, c] = min_p_value\n    df.columns = [col + '_x' for col in columns]\n    df.index = [col + '_y' for col in columns]\n    return df"]},{"cell_type":"markdown","id":"ef678565-d491-4ece-abf8-f3f8e73b36dd","metadata":{},"outputs":[],"source":["Let's perform the Granger Causality test on the price of BTCBUSD currency and NATR indicator.\n"]},{"cell_type":"code","id":"5a687293-9680-4cd2-b9f1-6b2213afcb8e","metadata":{},"outputs":[],"source":["grangers_causation_matrix(df[['Price', 'ADOSC']], 1, columns=['Price', 'ADOSC'])"]},{"cell_type":"markdown","id":"b2f1b23d-a15f-495e-9efc-ae1e1eb740b1","metadata":{},"outputs":[],"source":["#### How are the P-values to be read?\n","\n","If the P-value is less than 0.05, then, assuming a significance level of 0.05, we reject the null hypothesis that X does not generally cause Y.\n","Hence, the p-value for \u003cstrong\u003eADOSC_x\u003c/strong\u003e and \u003cstrong\u003eBTCBUSD_Price_y\u003c/strong\u003e in the above table is equal to 0.0 determining that NATR granger causes BTCBUSD price and that leads us to reject the null hypothesis.\n","\n","\u003cem\u003eTherefore, it is likely that the NATR movement will be useful in projecting BTCBUSD price.\u003c/em\u003e\n","\n","\u003cp\u003e\n","However, \u003cstrong\u003eADOSC_x\u003c/strong\u003e and \u003cstrong\u003eBTCBUSD_Price_y\u003c/strong\u003e have P-values of 0.0118. We cannot rule out the null hypothesis because the P-value does not equal or fall below 0.05.\n","\n","\u003cem\u003eIn other words, ADOSC can not be predicted from BTCBUSD price.\u003c/em\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"0470cfac-50ec-40b6-b16d-deaa3a8ea116","metadata":{},"outputs":[],"source":["Let's calculate Granger Causality Test for all available indicators pairs.\n"]},{"cell_type":"code","id":"db5722e1-b282-4bcd-8b86-7304481436c1","metadata":{},"outputs":[],"source":["cols = ['Price_y'] + [f\"{indicator}_y\" for indicator in indicators]\nidxs = ['Price_x'] + [f\"{indicator}_x\" for indicator in indicators]\n\ndf_granger = pd.DataFrame(columns=cols, index=idxs)\n\nfor (curr1, curr2) in itertools.permutations(['Price'] + indicators, 2):\n    df_test = df[[f\"{curr1}\", f\"{curr2}\"]]\n    res_df = grangers_causation_matrix(df_test, 1, variables=df_test.columns)\n    p1 = res_df[f\"{curr1}_x\"][f\"{curr2}_y\"]\n    p2 = res_df[f\"{curr2}_x\"][f\"{curr1}_y\"]\n    df_granger.loc[f\"{curr1}_x\", f\"{curr2}_y\"] = p1\n    df_granger.loc[f\"{curr2}_x\", f\"{curr1}_y\"] = p2\n\n# replace diagonal values with space char\nnp.fill_diagonal(df_granger.values, ' ')\n\ndf_granger"]},{"cell_type":"markdown","id":"6bd0e28c-4de9-4587-813d-f46895d2b93d","metadata":{},"outputs":[],"source":["Since we are interested in the influence and possible prediction of the price of our cryptocurrency with the help of indicators, we will consider the BTCBUSD price as a dependent variable \u003cstrong\u003ePrice_y\u003c/strong\u003e.\n","\n","Hence, the p-value for \u003cstrong\u003eVolume_x\u003c/strong\u003e, \u003cstrong\u003eADOSC_x\u003c/strong\u003e, \u003cstrong\u003eADOSC_x\u003c/strong\u003e, \u003cstrong\u003eNATR_x\u003c/strong\u003e, \u003cstrong\u003eTRANGE_x\u003c/strong\u003e and \u003cstrong\u003eBTCBUSD_Price_y\u003c/strong\u003e in the above table is less than 0.05 determining that these indicators granger causes BTCBUSD price and that leads us to reject the null hypothesis.\n","\n","\u003cem\u003eTherefore, it is likely that the all indicators movement will be useful in projecting BTCBUSD price.\u003c/em\u003e\n"]},{"cell_type":"markdown","id":"4099fcc3-e520-4448-9268-5940185cd720","metadata":{},"outputs":[],"source":["### Conclusion:\n"]},{"cell_type":"markdown","id":"a7ec3959-0911-47d6-9a5d-c0260ee46530","metadata":{},"outputs":[],"source":["\u003cp\u003eWe now have a better idea of what our data looks like and which variables are more related to our main BTCBUSD currency. Most of the indicators are some way related to our BTCBUSD currency and can be used to predict its value. We also have narrowed the most related indicators down to the following variables:\u003c/p\u003e\n","\u003cul\u003e\n","    \u003cli\u003eVolume\u003c/li\u003e\n","    \u003cli\u003eADOSC\u003c/li\u003e\n","    \u003cli\u003eNATR\u003c/li\u003e\n","\u003c/ul\u003e\n","\n","\u003cp\u003eAs we now move into building machine learning models to automate our analysis, feeding the model with variables that meaningfully affect our target variable will improve our model's prediction performance.\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"43ad5f61-c5d6-422b-aa91-0228d938e69b","metadata":{},"outputs":[],"source":["## Save Dataset\n","\u003cp\u003e\n","Correspondingly, Pandas enables us to save the dataset to csv. By using the \u003ccode\u003edataframe.to_csv()\u003c/code\u003e method, you can add the file path and name along with quotation marks in the brackets.\n","\u003c/p\u003e\n","\u003cp\u003e\n","Let's save the dataframe \u003cstrong\u003edf\u003c/strong\u003e as \u003cstrong\u003eBTCBUSD_trades_1m.csv\u003c/strong\u003e in order to use it in the following modules. You may use the syntax below, where \u003ccode\u003eindex = True\u003c/code\u003e means the row names will be written as well.\n","\u003c/p\u003e\n"]},{"cell_type":"code","id":"55bc1a90-04f4-41cd-92b2-5ddb61139eb6","metadata":{},"outputs":[],"source":["df.to_csv(\"BTCBUSD_trades_1m.csv\", index=True)"]},{"cell_type":"markdown","id":"4b5a57c4-9d59-44c4-a483-c685e58eea88","metadata":{},"outputs":[],"source":["Great! You have successfully reached the end!\n"]},{"cell_type":"markdown","id":"1f9d7ed6-5df0-4bca-a581-7b03ab76fa6d","metadata":{},"outputs":[],"source":["### Thank you for completing this lab!\n","\n","## Authors\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaryna_beida?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX043BEN2378-2023-01-01\"\u003eYaryna Beida\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX043BEN2378-2023-01-01\"\u003eProf. Yaroslav Vyklyuk, DrSc, PhD\u003c/a\u003e\n","\n","\u003ca href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX043BEN2378-2023-01-01\"\u003eProf. Mariya Fleychuk, DrSc, PhD\u003c/a\u003e\n","\n","\n","## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n","| ----------------- | ------- | ---------- | ---------------------------------- |\n","|     2023-03-11    |   1.0   |Yaryna Beida| Lab created                        |\n","\n","\u003chr\u003e\n","\n","## \u003ch3 align=\"center\"\u003e © IBM Corporation 2023. All rights reserved. \u003ch3/\u003e\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}