{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "83c0ac51-56e2-4c25-8f54-67df1e7e15b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"400\" alt=\"cognitiveclass.ai logo\">\n</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "367d59d3-4b2e-49ad-9e55-d4f7d2571d14",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Investigation of MATIC/BUSD cryptocurrency based on ADOSC, NATR, TRANGE indicators\n\n## Financial services. Lab 5. Classification in finances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae23979-a0c1-4455-9042-9b3cce188f41",
      "metadata": {},
      "outputs": [],
      "source": [
        "The purpose of this lab is to master classification clients in banking for machine learning models.\n\nAfter completing this lab you will be able to:\n\n1. Preprocess (normilize and transform categorical data) and create DataSet\n2. Features selection\n3. Make classification of clients\n4. Visualize decision tree of classification model  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a128e18-f9b3-4ba8-837c-539abd1f39ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Outline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b298eb7-2a53-431f-ba59-8cb6a859b4b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "* Materials and Methods\n* General Part\n  * Import Libraries\n  * Load the Dataset\n  * Data preparation\n      * Data transformation\n      * Encoding and Normalization\n  * Features selection\n      * Chi-Squared Statistic\n      * Mutual Information Statistic\n      * Feature Importance\n  * Classification models\n      * Train and Test DataSets creation\n      * Extra Trees Classifier\n      * Logistic regression \n  * Decision tree \n      * Build model\n      * Visualization of decision tree\n* Tasks\n* Authors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa04a448-571b-4f05-94e4-5d21974b489a",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Materials and Methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293762dd-b486-4dfd-aca9-07b46be37cda",
      "metadata": {},
      "outputs": [],
      "source": [
        "During the work, the task of a preliminary analysis of cryptocurrency price level based on numerical indicator values and its division into categories by levels.\n\nIn this lesson, we will try to give answers to a set of questions that may be relevant when analyzing banking data:\n\n1. What are the most useful Python libraries for classification analysis?\n2. How to transform category data?\n3. How to create DataSet?\n4. How to do features selection?\n5. How to make, fit and visualize classification model?\n\nIn addition, we will make the conclusions for the obtained results of our classification analysis to discover wether indicators can be used in cryptocurrency price prediciton.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1e2a76e-9a73-455e-9ca3-49b4223da288",
      "metadata": {},
      "outputs": [],
      "source": [
        "[Scikit-learn](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01) (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.\n\nLet's install <em>scikit-learn</em> and other needed modules:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "015e7263-6371-4c8b-9d8d-6c4641741c5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "! conda install -c conda-forge scikit-learn -y\n! conda install python-graphviz -y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dae8e34-a3e6-4c56-ba5e-487a1a138f2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c2bd91d-32f8-46bc-860e-c63b96562ea2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Import the libraries necessary to use in this lab. We can add some aliases to make the libraries easier to use in our code and set a default figure size for further plots. Ignore the warnings.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d8b9b794-4db2-4f1c-bc0a-69e078781068",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport graphviz\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (8, 6)\n# Data transformation\nfrom sklearn.preprocessing import LabelEncoder, OrdinalEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n# Features Selection\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2, mutual_info_classif\n# Classificators\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn import tree\npd.set_option(\"precision\", 2)\npd.options.display.float_format = '{:.2f}'.format\n# warnings deactivate\nimport warnings\nwarnings.filterwarnings('ignore')\n# for better visualization\n# from sklearn import set_config\n# set_config(display = 'diagram')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc50630e-e300-4e6a-811c-065f8daf4a43",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Load the Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b87634e2-816d-4c1e-9b0e-f1d8bdb01e06",
      "metadata": {},
      "outputs": [],
      "source": [
        "We will use the same DataSet like in previous labs. Therefore next some steps will be the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7801c6ac-faea-41c4-952a-c14d35a9d3e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "First, we assign the URL of the dataset to <code>\"path\"</code>. \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "59232290-8509-44ee-afd9-15e57e39747e",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Intela-GPXX0HL7EN/labs/MATICBUSD_lab4.csv' "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0550c30b-10eb-4cdb-ae06-b700344b2255",
      "metadata": {},
      "outputs": [],
      "source": [
        "Then use the Pandas method <code>read_csv()</code> to load the data from the web address and set dataframe index column type to <strong>datetime</strong> using <code>pd.to_datetime()</code> method for correct time series analysis. \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3ff7644b-1db6-4c55-b241-567c717fe5dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(path)\ndf.Ts = pd.to_datetime(df.Ts)\ndf.set_index('Ts', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "id": "e40a94f4-7721-413a-9e39-ec2a08bebe84",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "75c331dd-deaf-49d2-95ad-4b3bcac18a74",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f480fd0-878e-4523-b679-c63b0ca1df4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see DataSet consist 12 columns. 'Avg_price' column will be the target in further classification implementation. Also DataSet consist 50881 rows. In previous labs we investigated input columns. In our classification models we will use the following features:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f7a2c94-def2-470a-97be-5028a6e31f5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Input features (column names):\n1. `Volume` - the total number of units of the asset traded on all exchanges within a particular time period <em>(numeric)</em>\n2. `ADOSC` - an volume-based indicator to measure the cumulative flow of money into and out of an asset <em>(numeric)</em>\n3. `NATR` - an indicator measuring the volatility level <em>(numeric)</em>\n4. `TRANGE` - a technical indicator which measures the daily range plus any gap from the closing price of the preceding day<em>(numeric)</em>\n5. `Volume_binned` - Volume values divided into five category based on their level <em>(categorical: `Low`, `Low-Medium`, `Medium`, `Medium-High`, `High`)</em>\n6. `Avg_price` - Avg_price values divided into five category based on their level <em>(categorical: `Low`, `Low-Medium`, `Medium`, `Medium-High`, `High`)</em>\n7. `NATR_binned` - NATR values divided into five category based on their level <em>(categorical: `Low`, `Low-Medium`, `Medium`, `Medium-High`, `High`)</em>\n\nOutput feature (desired target):\n\n1. `Avg_proce-binned` - determine in which price category cryptocuttency will be\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0229b502-3554-42fd-8dd8-1ce6c00b609b",
      "metadata": {},
      "outputs": [],
      "source": [
        "Our goal is create the classification model that can predict  the cryptocurrency price level. To do this we must analize and prepare data for such type of model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf071682-4f7e-4c1f-991f-40e9a552ab2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Data preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc1bc05c-5631-492d-8434-20381b118a3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Data transformation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84e02a40-f6ae-43f5-aa94-e51bb5df67b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "First of all we should investigate how Pandas recognized types of features and make binned columns as type \"categorical\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "19622fb7-19e2-414a-b794-b127985bc1e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "col_cat = list(df.select_dtypes(include=['object']).columns)\ndf.loc[:, col_cat] = df[col_cat].astype('category')\ndf.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd1cd70-adc9-4354-83b0-a87b599f59a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "To see the unique values of exact feature (column) we can use <code>unique()</code> function:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "bbbcdaf1-d643-4216-9eda-29a1bb08ee9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['NATR-binned'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd306a2-d9e5-4d98-b83e-643ce4c02ec1",
      "metadata": {},
      "outputs": [],
      "source": [
        "As was signed earlier the dataset contains 50881 objects (rows), for each of which 12 features are set (columns), including 1 target feature (y). 4 features, including target are categorical. These data type of values cannot use for classification. We must transform it to int or float. \nTo do this we can use **[LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)** and **[OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)**. These functions can encode categorical features as an integer array.\n\nFirs of all we separate DataSet on input and output (target) DataSets:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "21638d6a-7d10-44a2-bab1-fc136e590a07",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df[['Volume', 'NATR', 'Volume-binned',  'NATR-binned']] \ny = df['Avg_price-binned']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08326521-055c-4847-b4b8-49d289ed0ff4",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Encoding and Normalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a16fc539-884f-41c9-b7aa-7ac54d172a33",
      "metadata": {},
      "outputs": [],
      "source": [
        "Than create list of categorical fields and transform thair values to int arrays:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0b94d3b7-ac93-400c-b3c7-6ce9dba76208",
      "metadata": {},
      "outputs": [],
      "source": [
        "col_cat = ['Volume-binned', 'NATR-binned']\noe = OrdinalEncoder()\noe.fit(X[col_cat])\nX_cat_enc = oe.transform(X[col_cat])\n#to dataset\nX_cat_enc = pd.DataFrame(X_cat_enc)\nX_cat_enc.columns = col_cat\nX_cat_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab37bbda-3684-438a-8239-29e82f1b9e11",
      "metadata": {},
      "outputs": [],
      "source": [
        "Numerical fields can have different scale and can consists negative values. These will lead to round mistakes and exeptions for some AI methods. To avoid it these features must be normalized.\n\nLet's create list of numerical fields and normilize it using by **[MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)**:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8234d233-331e-459d-9b73-aee1080708ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "col_num = ['Volume',  'NATR']\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nX_num_enc = scaler.fit_transform(X[col_num])\nX_num_enc = pd.DataFrame(X_num_enc)\nX_num_enc.columns = col_num\nX_num_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12ebff69-f3d0-428d-88c3-eaa8bfdad970",
      "metadata": {},
      "outputs": [],
      "source": [
        "Then we should concatenate these DataFrames in one input DataFrame:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "873e1406-7e1a-4cc5-8ced-4792756faabf",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_enc = pd.concat([X_cat_enc, X_num_enc], axis=1)\nx_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776c46b3-b4fc-44ef-82a3-b434c73eca07",
      "metadata": {},
      "outputs": [],
      "source": [
        "The same transformation we must do for target field:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "83308c9c-0581-4134-8101-aa449710584a",
      "metadata": {},
      "outputs": [],
      "source": [
        "le = LabelEncoder()\nle.fit(y)\ny_enc = le.transform(y)\ny_enc = pd.Series(y_enc)\ny_enc.columns = y.name\ny.to_frame()"
      ]
    },
    {
      "cell_type": "code",
      "id": "74435c28-a610-4a71-92e2-441716b6da08",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_enc.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a324c5ee-6bab-43ff-9607-c49134ad47b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see values 'High' was changed on 0, 'Medium-High' on 4, 'Medium' on 3, 'Low-Medium' on 2 , 'Low' on 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330cc427-a854-4a19-8685-630769594f73",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Features selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1c65fb5-4882-4c21-8cde-6d358d0db5c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "As was signed before input fields consists 8 features. Of coure some of them are more significant for classification. \n\nThere are two popular feature selection techniques that can be used for categorical input data and a categorical (class) target variable:\n* Chi-Squared Statistic.\n* Mutual Information Statistic.\n\nLet’s take a closer look at each in turn. To do this we can use **[SelectKBest](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2444f2f3-e194-4b16-8912-b0b2730214cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Chi-Squared Statistic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09573bf9-fa8d-4bc0-bf8d-054c7dc8a6e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "<em><strong>Pearson’s chi-squared statistical hypothesis test</strong></em> is an example of a test for independence between categorical variables.\n\nYou can learn more about this statistical test in the tutorial:\n*   [A Gentle Introduction to the Chi-Squared Test for Machine Learning](https://machinelearningmastery.com/chi-squared-test-for-machine-learning/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01).\n\nThe results of this test can be used for feature selection, where those features that are independent of the target variable can be removed from the dataset.\n\nThe scikit-learn machine library provides an implementation of the chi-squared test in the **[chi2()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01#sklearn.feature_selection.chi2)** function. This function can be used in a feature selection strategy, such as selecting the top k most relevant features (largest values) via the SelectKBest class.\n\nFor example, we can define the <em>SelectKBest class</em> to use the <code>chi2()</code> function and select all (or most significant) features, then transform the train and test sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe723ca-9a56-4488-abe0-8e75b5f5badd",
      "metadata": {},
      "outputs": [],
      "source": [
        "Apply SelectKBest class to extract features:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2893653a-cee9-43ed-afd2-b98bac9c9f08",
      "metadata": {},
      "outputs": [],
      "source": [
        "bestfeatures = SelectKBest(score_func=chi2, k='all')\nfit = bestfeatures.fit(x_enc,y_enc)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d19319-1e9b-46d9-b426-0ff666e2017f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Concat two dataframes for better visualization:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f4a1e2fb-f994-438e-b9e1-e9091dc71b0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "featureScores = pd.concat([dfcolumns, dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nfeatureScores.sort_values(by=['Score'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d98a438-0357-42a0-bf01-aba9ef039684",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Mutual Information Statistic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d52b1e-fe17-41d0-8bb1-f723a999bdba",
      "metadata": {},
      "outputs": [],
      "source": [
        "<em><strong>Mutual information</strong></em> from the field of information theory is the application of information gain (typically used in the construction of decision trees) to feature selection.\n\n<em>Mutual information<em> is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\n\n[You can learn more about mutual information in the following tutorial.](https://machinelearningmastery.com/information-gain-and-mutual-information?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)\n\nThe scikit-learn machine learning library provides an implementation of mutual information for feature selection via the **[mutual_info_classif()](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01#sklearn.feature_selection.mutual_info_classif)** function.\n\nLike <code>chi2()</code>, it can be used in the SelectKBest feature selection strategy (and other strategies).\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "fbf1e80e-03a8-4a7d-b6a2-d9b05d177691",
      "metadata": {},
      "outputs": [],
      "source": [
        "bestfeatures = SelectKBest(score_func=mutual_info_classif, k='all')\nfit = bestfeatures.fit(x_enc,y_enc)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\nfeatureScores = pd.concat([dfcolumns, dfscores],axis=1)\nfeatureScores.columns = ['Specs','Score']  #naming the dataframe columns\nfeatureScores.sort_values(by=['Score'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9115376-394c-4917-98e2-06587e099a4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see these 2 function select almost the same significant features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea23df9d-8880-443d-84ef-882225d73883",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can see that categorical dataframe columns have the most significant impact. Thus, let's consider only them as inputs for predicting model.  \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "7e5d7932-4199-4323-9215-3126294de994",
      "metadata": {},
      "outputs": [],
      "source": [
        "x_enc = x_enc[x_enc.columns[:4]]\nx_enc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bdc152b-ad15-4953-9f1e-9dc52e7e88ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Feature Importance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f69b377a-481d-4161-894a-0b6a07781817",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can get the feature importance of each feature of your DataFrame by using the feature importance property of the exact classification model.\n\n<em>Feature importance</em> gives you a score for each feature of your data, the higher the score more important or relevant is the feature towards your output variable.\n\n<em><strong>For example:</strong></em>\n\nFeature importance is an inbuilt class that comes with **[Tree Based Classifiers](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)**, we will be using Extra Tree Classifier for extracting the top 10 features for the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4ad74e-6fde-4a33-b51d-9579ea5190c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's create and fit the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "4818efad-a976-4888-95cc-a38148fba23e",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ExtraTreesClassifier()\nmodel.fit(x_enc,y_enc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfbfa4c9-eb74-4ad9-9124-2b2b8dbb6cc3",
      "metadata": {},
      "outputs": [],
      "source": [
        "Use inbuilt <code>feature_importances</code> method of tree based classifiers:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9d57240c-fe2e-4be9-bc78-bcf13cdad4c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e4df036-e2b1-480a-8056-c6d2cd436d6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's transform it into Series and plot graph of feature importances for better visualization:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a0637ecd-b76e-4f84-a453-1754d9e9b2f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_importances = pd.Series(model.feature_importances_, index=x_enc.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0136fc64-c77e-453a-9f31-b59150cc644d",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can see that for <em>Extra Tree Classifier</em> impotance of features are the same as in previous cases. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "277f4a80-54d2-4861-9d81-84315fd98201",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Classification models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "481f3da4-1929-47c7-8cb0-31fe15e8845f",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Train and Test DataSets creation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61760d75-e5c7-453c-bc8b-ed91904bb3ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "First of all we must separate DataSets for train and test DataSets for calculate accuracy of models. To do this we can use **[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)**. \n\nLet's separate DataSets in <em>0.33</em> proportion <em>train/test<em>:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "69ee83bb-b948-4fb5-9a14-1d00266c2d8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_enc, y_enc, test_size=0.33, random_state=1)\nprint(\"X_train:\", X_train.shape)\nprint(\"X_test:\", X_test.shape)\nprint(\"y_train:\", y_train.shape)\nprint(\"y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43a36395-0034-42a3-a695-af58f69144b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Extra Trees Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed2b34a-13fc-4315-80d1-688b2252e98b",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>What is an extra tree classifier?</h4>\n\n<strong><em>Extra trees</em></strong> (short for extremely randomized trees)</em> is an ensemble supervised machine learning method that uses decision trees and perform their averaging to improve the predictive accuracy and control overfitting.\n\nLet's create and fit ExtraTreesClassifier on our train dataset and calculate accuracy of classification:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6aef6fbc-cc45-4961-abca-11c5427185d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ExtraTreesClassifier()\nmodel.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6b0008f-f193-44d0-ba49-0057e5723842",
      "metadata": {},
      "outputs": [],
      "source": [
        "Evaluate the model on test data for obtain predictions:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "5f3adaa0-54fb-4d38-8861-eab8f57acc41",
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat = model.predict(X_test)\nprint(yhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f78437-7526-4335-97ff-2788bcd49374",
      "metadata": {},
      "outputs": [],
      "source": [
        "Evaluate accuracy: \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9d9884cc-cd07-4f5f-8239-862f1b09be85",
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(y_test, yhat)\nprint('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f89180a-5263-407a-abe7-65eb5aa2827a",
      "metadata": {},
      "outputs": [],
      "source": [
        "There are many different techniques for scoring features and selecting features based on scores. <em>How do you know which one to use?</em>\n\nA robust approach is to evaluate models using different feature selection methods (and numbers of features) and select the method that results in a model with the best performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfd89f4c-fa64-4479-894f-cae34bb6dcd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Logistic regression \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd66548d-e0ff-41c0-9e35-671fb4506bfc",
      "metadata": {},
      "outputs": [],
      "source": [
        "**[Logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)** is a good model for testing feature selection methods as it can perform better if irrelevant features are removed from the model. We will use this model in absolutelly similar way like previous one.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "c7aa7108-e649-4e84-b3c0-7587ece0f716",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(solver='lbfgs')\nmodel.fit(X_train, y_train)\nyhat = model.predict(X_test)\naccuracy = accuracy_score(y_test, yhat)\nprint('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d869a1c6-21c8-4e43-8b0b-d0ea1373c4dc",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary> \n<code>    \nmodel = LogisticRegression(solver='lbfgs')\nmodel.fit(X_train, y_train)\nyhat = model.predict(X_test)\naccuracy = accuracy_score(y_test, yhat)\nprint('Accuracy: %.2f' % (accuracy*100))\n    </code>\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab6519a8-a521-49d3-a597-40cca5985431",
      "metadata": {},
      "outputs": [],
      "source": [
        "As you can see accuracy did not improve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3cdcd4-3f88-4954-a87f-7c57ac3ced6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Decision tree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6fe60b4-feec-4aae-a47c-4d826c4e0c9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "The biggest drawback of the previous methods is the inability to visualize or justify the decision.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ddf3e0-4701-4a67-90b7-ad414395af20",
      "metadata": {},
      "outputs": [],
      "source": [
        "<strong><em>Decision trees</em></strong> are a popular supervised learning method for a variety of reasons. \n\nBenefits of decision trees include that <em>they can be used for both regression and classification</em>, they don’t require feature scaling, and they are relatively easy to interpret as you can visualize decision trees. This is not only a powerful way to understand your model, but also to communicate how your model works. \n\nConsequently, it would help to know how to make a visualization based on your model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c09bfb0-e0e4-4776-a92f-92ec41933282",
      "metadata": {},
      "outputs": [],
      "source": [
        "<em>A **[Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)**</em> is a supervised algorithm used in machine learning. It is using a binary tree graph (each node has two children) to assign for each data sample a target value. The target values are presented in the tree leaves. To reach to the leaf, the sample is propagated through nodes, starting at the root node. In each node a decision is made, to which descendant node it should go. \n\nA decision is made based on the selected sample’s feature. Decision Tree learning is a process of finding the optimal rules in each internal tree node according to the selected metric.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baaf1d92-a137-42d2-875b-cff68fbfd792",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Build model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9a857e-463e-468d-9301-b7f66c54acc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "This metod allows also to calculate features impotance.\nLet's calculate them. Choice best 10 of them. Refit the model and visualize decision tree.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6e8dabdd-1722-4f5c-9462-e78e98bebf47",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = DecisionTreeClassifier()\nmodel.fit(X_train, y_train)\nyhat = model.predict(X_test)\naccuracy = accuracy_score(y_test, yhat)\nprint('Accuracy: %.2f' % (accuracy*100)) "
      ]
    },
    {
      "cell_type": "code",
      "id": "350e6bdc-0b85-4b46-b1ea-4f020b22c243",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Features impotance:\", model.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1395cace-a142-41a5-b899-9f27fbb22515",
      "metadata": {},
      "outputs": [],
      "source": [
        "Plot graph of feature importances for better visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "30629585-10dd-42d1-903d-22c9d63527e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_importances = pd.Series(model.feature_importances_, index=x_enc.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca603b2-1aa5-42f2-bd75-ff9433b33e7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Visualization of decision tree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43e633f0-ef05-43e1-81c4-ca36ad640ab2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's visualize decision tree.\nThere are some ways to do it:\n\n*   Text visualization\n*   Plot tree\n*   Graph visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a45fb1-41fc-47c3-83fe-4521bddb4ada",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Text visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e1600ad1-40c1-4f21-8032-1d00073cadb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "text_representation = tree.export_text(model, max_depth=3)\nprint(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff2bf77-7798-4b14-8ab4-1e1b741f6122",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can save it into file:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e3fa1350-8533-4fae-8148-772e23cb8f04",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"decistion_tree.log\", \"w\") as fout:\n    fout.write(text_representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41a0676-84de-4019-a673-504988dcc011",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Plot tree\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a76e9c2-6a17-4acd-85c0-c13f7b59a5fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "You can plot tree using by two different way:\n1. <code>**[plot_tree()](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX01KTEN2525-2023-01-01)**</code>\n2. <code>export_graphviz()</code> from <em>graphviz library <em>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc47a086-0f52-4232-b576-58c75564a498",
      "metadata": {},
      "outputs": [],
      "source": [
        "Because of slow rendering <code>plot_tree</code> implementation can take some time: \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8b2fd9b6-8718-498e-92d2-7f068f502aac",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(25,20))\n_ = tree.plot_tree(model,\n               feature_names = x_enc.columns, \n               class_names = y.unique(),\n               filled = True,\n               max_depth=3)"
      ]
    },
    {
      "cell_type": "code",
      "id": "6db9efaf-f648-430e-9c44-1156b877eab6",
      "metadata": {},
      "outputs": [],
      "source": [
        "fig.savefig('decision_tree.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc2dfdd0-a940-4a8a-9d3c-c6f529296d2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's visualize our decision tree in a graph form using <em>graphviz</em> module:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3a3ed199-b164-4f4f-8afd-967ba726f3cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "dot_data = tree.export_graphviz(model,\n               feature_names = x_enc.columns, \n               class_names = y.unique(),\n               filled=True,\n               max_depth=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70bf5144-8b74-4dc9-a55d-561bbd672eb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "After creation you can draw graph:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b98c8e57-5258-4d47-85c3-7c54c753799e",
      "metadata": {},
      "outputs": [],
      "source": [
        "graph = graphviz.Source(dot_data, format=\"png\") \ngraph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c71328-fd7b-40ec-8522-f4743323e723",
      "metadata": {},
      "outputs": [],
      "source": [
        "And render it into file:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "589cd150-2f35-4838-86bb-2be46e37f895",
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.render(\"decision_tree\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44f835ef-f174-41e0-a150-a5ec45814eef",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Conclusions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80c0dc8a-7113-42f7-a568-51acdaf69619",
      "metadata": {},
      "outputs": [],
      "source": [
        "In this lab we learned to do preliminary data processing. In particular, change data types, normalize and process categorical data. It was shown how to make feature selection by different methods. Learned how to build training and test DataSets. Shows how to work with different classifiers. It was also shown how to visualize a decision tree.\n\nAs a result, the accuracy of all three classification models did not exceed 46%. <em>This indicates that linear models in economics and finance generally do not work well and are not effective.</em> In the following courses, we will consider the effectiveness of nonlinear models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2960c19b-3012-4bb7-8cc6-d91acea9de87",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Tasks\n\nTo consolidate knowledge, we will perform several tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f731e492-834a-472a-8d73-739b92d36d79",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n\n<h1>Question 1: </h1>\n\nCreate an ExtraTreesClassifier object called \"model\".\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d1c36983-8979-49b4-8a61-8d1ec18f06a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c0a53f-1c1b-4bba-a713-d32489b5289a",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary> \n<code>model = ExtraTreesClassifier()</code>\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a87a645-204a-4b4a-9bae-ec63859ae6b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n\n<h1>Question 2: </h1>\n\nCreate user function <cod>def model_ac(x_train, y_train, x_test, y_test, clf)</code> that will calculate accuracy of defined classificator model.\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "3af6f8d6-3d32-41f4-b20f-6b0d5620e1f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfffcfc8-2b48-42f9-8b4a-f4152e55b93e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary> \n<code>\n    def model_ac(x_train, y_train, x_test, y_test, clf):\n    model.fit(x_train, y_train)\n    yhat = model.predict(x_test)\n    accuracy = accuracy_score(y_test, yhat)\n    return accuracy\n</code>\n</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0c634da9-63f6-4b91-92f0-625d62bdcf13",
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Accuracy: %.2f' % (model_ac(X_train, y_train, X_test, y_test, model)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f7e9097-a448-47cc-88f5-c7529df5cb45",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n\n<h1>Question 3: </h1>\n\nCreate user function that will calculate features impotance of defined classificator model.\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "09c8b623-82e7-4040-8d7b-0402ab816aff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "920264a9-d23d-4a8d-b213-ee58fc7447c6",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary> \n<code>    \n    model.fit(x_train, y_train)\n    feat_importances = pd.Series(model.feature_importances_, index=x_enc.columns)\n    return feat_importances.sort_values(ascending=False)\n    </code>\n</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e112cbab-2c36-4f55-ba90-932628ffdd21",
      "metadata": {},
      "outputs": [],
      "source": [
        "imp = model_imp(X_train, y_train, model)\nprint(imp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea0e226-e8bb-470a-b285-9195eb55c2f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n\n<h1>Question 4: </h1>\n\nBuild plot that show accuracy of defined model depedence on numbers of input features.\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "75e12773-bf64-403b-8478-5f844cad8e1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "586b4716-f435-4c91-9544-2c80878f27b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click <b>here</b> for the solution</summary> \n<code>    \ncol = []\nac = []\nfor c in imp.index:\n    col.append(c)\n    ac.append(model_ac(X_train[col], y_train, X_test[col], y_test, model))\n    print('Input fields: ', len(col), 'Accuracy: %.2f' % (ac[-1]*100))\nac = pd.Series(ac)\nac.plot()\n    </code>\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6af6128-ea5d-474f-87f4-9d55456f4382",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing Lab 5!**\n\n## Authors\n\n<a href=\"https://author.skills.network/instructors/oleh_lozovyi?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Oleh Lozovyi</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">Joseph Santarcangelo</a>\n\n\n<a href=\"https://www.linkedin.com/in/fiorellawever/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">Fiorella Wenver</a>\n\n<a href=\"https:// https://www.linkedin.com/in/yi-leng-yao-84451275/ \" target=\"_blank\" >Yi Yao</a>\n\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By   | Change Description                                         |\n| ----------------- | ------- | -------------| ---------------------------------------------------------- |\n|     2023-03-29    |   1.0   | Oleh Lozovyi | Lab created                                                |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. <h3/>\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "398116fd-5931-4c91-8e5c-135f65375944",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}