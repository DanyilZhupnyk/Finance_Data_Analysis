{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0b53da10-9e1d-4ac8-9322-48980a6b4154",
      "metadata": {},
      "outputs": [],
      "source": [
        "<center>\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n</center>\n\n# Financial Services: Lab 2. Dataset wrangling (on the example of MATIC/BUSD and several technical indicators:  ADOSC, NATR, TRANGE)\n\nThe tasks:\n* To find empty cells and handle missing values;\n* Analyze data format, find the wrong format and correct data format;\n* Standardize and normalize data series.\n\nEstimated time needed: **30** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Handle missing values\n*   Correct data format\n*   Standardize and normalize data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ab4a0e4-19a4-4a46-a19a-daea8a167a42",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ul>\n    <li>Identify and handle missing values\n        <ul>\n            <li>Identify missing values</li>\n            <li>Deal with missing values</li>\n            <li>Correct data format</li>\n        </ul>\n    </li>\n    <li>Data standardization</li>\n    <li>Data normalization (centering/scaling)</li>\n    <li>Binning</li>\n    <li>Indicator variable</li>\n    <li>Resample data</li>\n</ul>\n\n</div>\n\n<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27d4ab85-eb4b-4ff2-8c41-d1bda697dae3",
      "metadata": {},
      "outputs": [],
      "source": [
        "## What is the purpose of data wrangling?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d19d1c0b-bd1f-4228-ace7-519e4918c2bd",
      "metadata": {},
      "outputs": [],
      "source": [
        "Data wrangling is the process of converting data from the initial format to a format that may be better for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afc0e7f3-59ca-43a0-8f27-ba13ecb51604",
      "metadata": {},
      "outputs": [],
      "source": [
        "### What is the Avarage price of MATICcoin in different currency?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f4c980-2b2b-423a-9197-a66f0df0a6d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Import data\n<p>\nYou can find the \"MATICBUSD trades Dataset\" from the following link:\n<a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0B59EN/labs/MATICBUSD_trades_1m%20(1).csv\" target=\"_blank\">https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0B59EN/labs/MATICBUSD_trades_1m%20(1).csv</a>\n\nWe will be using this dataset throughout this course.\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fc046a-04dd-4a3e-b3e7-66b2035df279",
      "metadata": {},
      "outputs": [],
      "source": [
        "If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "53190a30-637c-4ac3-aae6-3c1e41179e5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#If you run the lab locally using Anaconda, you can load the correct library and versions by uncommenting the following:\n#install specific version of libraries used in lab\n! conda install pandas -y\n! conda install numpy -y"
      ]
    },
    {
      "cell_type": "code",
      "id": "faa18a5a-d76f-4068-b0bc-d2cc03a9dd9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport matplotlib.pylab as plt\nimport numpy as np\n\n%matplotlib inline\nimport matplotlib as plt\nfrom matplotlib import pyplot\n\n#set values precision as 6\npd.set_option(\"display.precision\", 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f3db9c-7128-4ee4-bdda-20153fa0e741",
      "metadata": {},
      "outputs": [],
      "source": [
        "This function will download the dataset into your browser\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610f9752-f67e-4fef-bcc1-a6e7c775e0d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Reading the dataset from the URL and adding the related headers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30eeb120-860a-4d3a-b47c-5e0079385f13",
      "metadata": {},
      "outputs": [],
      "source": [
        "First, we assign the URL of the dataset to \"filename\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efcb8c3b-6533-4ce9-973e-2145879bb500",
      "metadata": {},
      "outputs": [],
      "source": [
        "This dataset was hosted on IBM Cloud object. Click <a href=\"https://cocl.us/corsera_da0101en_notebook_bottom?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">HERE</a> for free storage.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "231774ef-2efb-4e7e-a803-bebdcee12245",
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-GPXX0B59EN/labs/MATICBUSD_trades_1m%20(1).csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0adeec66-ba14-46d6-bb32-1bae9c57fc29",
      "metadata": {},
      "outputs": [],
      "source": [
        "Then, we create a Python list <b>headers</b> containing name of headers.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "0a547b57-f8a6-447b-82ca-6bd4277fda01",
      "metadata": {},
      "outputs": [],
      "source": [
        "headers = [\"Ts\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Avg_price\", \"ADOSC\", \"TRANGE\", \"NATR\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55cd2f1d-763b-45b5-a3cf-482d9eb9c153",
      "metadata": {},
      "outputs": [],
      "source": [
        "Use the Pandas method <b>read_csv()</b> to load the data from the web address. Set the parameter  \"names\" equal to the Python list \"headers\".\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "10960a09-9bbc-4c16-8c42-e6357b8ffd97",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(filename, index_col = 0, names = headers, skiprows = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0a1986a-a62f-4f4d-b591-11ee2cea09ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "Use the method <b>head()</b> to display the first five rows of the dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "61d253f3-e3df-455e-9890-6c47fc790f66",
      "metadata": {},
      "outputs": [],
      "source": [
        "# To see what the data set looks like, we'll use the head() method.\ndf.index = df.index.astype(\"datetime64[ns]\")\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33d7dd17-e5a8-4bc4-b45c-a38b8c17a1ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Reading the dataset from the URL and adding the related headers\nAs we can see, several question marks appeared in the dataframe; those are missing values which may hinder our further analysis.\n\n\n<div>So, how do we identify all those missing values and deal with them?</div> \n\n\n<b>How to work with missing data?</b>\n\nSteps for working with missing data:\n\n<ol>\n    <li>Identify missing data</li>\n    <li>Deal with missing data</li>\n    <li>Correct data format</li>\n</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1f3c20-32b6-45a9-b28b-506fa0a7c528",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Identify and handle missing values\n\n### Identify missing values\n#### Convert missed or wrong data to NaN\nIn the trades dataset, missing data comes with the question mark \"?\", text or negative values.\nWe replace that with NaN (Not a Number), Python's default missing value marker for reasons of computational speed and convenience. Here we use the function: \n <pre>.replace(A, B, inplace = True) </pre>\n to replace A by B or\n <pre>.mask(condition, new value, inplace = True)</pre>\n to change value by some condition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "261fd441-a04b-4743-bfe1-2bd833a86176",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Evaluating for Missing Data\n\nThe missing values are converted by default. We use the following functions to identify these missing values. There are two methods to detect missing data:\n\n<ol>\n    <li><b>.isnull()</b></li>\n    <li><b>.notnull()</b></li>\n</ol>\nThe output is a boolean value indicating whether the value that is passed into the argument is in fact missing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "af7dbc9d-1f7e-4124-a58c-e6f9f9127798",
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data = df.isnull()\nmissing_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "247b96ba-493c-4b41-9758-47f1caa6b5a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "\"True\" means the value is a missing value while \"False\" means the value is not a missing value.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb37702c-a0b8-407c-92b3-01acdc526e01",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Count missing values in each column\n<p>\nUsing a for loop in Python, we can quickly figure out the number of missing values in each column. As mentioned above, \"True\" represents a missing value and \"False\" means the value is present in the dataset.  In the body of the for loop the method \".value_counts()\" counts the number of \"True\" values. \n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e4d9c1af-10a0-46cc-93c7-cceb629ed870",
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e6eb0c3-4e19-4495-8f07-c0198ef72836",
      "metadata": {},
      "outputs": [],
      "source": [
        "Based on the summary above, each column has 50891 rows of data and eight of the columns containing missing data, for example:\n\n<ol>\n    <li>\"Close\" : 2597 missing data</li>\n    <li>\"ADOSC\":  9 missing data</li>\n    <li>\"NATR\": 10440 missing data</li>\n</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ba90d44-e934-4d3f-aee4-76599184e1cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Deal with missing data\n<b>How to deal with missing data?</b>\n\n<ol>\n    <li>Drop data<br>\n        a. Drop the whole row<br>\n        b. Drop the whole column\n    </li>\n    <li>Replace data<br>\n        a. Replace it by mean<br>\n        b. Replace it by frequency<br>\n        c. Replace it based on other functions\n    </li>\n</ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ca02cc-885a-42c1-aaf5-4670ac7b3012",
      "metadata": {},
      "outputs": [],
      "source": [
        "Whole columns should be dropped only if most entries in the column are empty. In our dataset, none of the columns are empty enough to drop entirely.\nWe have some freedom in choosing which method to replace data; however, some methods may seem more reasonable than others. \n\nOur data is linked to time, so we can not drop rows to save data quality for future analysis. Also not the best way to restore our data is to replace it by mean value.\nSo we will use an interpolation (and also delete some rows) to restore it."
      ]
    },
    {
      "cell_type": "code",
      "id": "b08b7563-c984-4a75-b386-2240e2e17019",
      "metadata": {},
      "outputs": [],
      "source": [
        "#set output precision on 6 digits\npd.set_option(\"display.precision\", 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2efa24e-2c95-4450-8e3e-19bbf5e58c63",
      "metadata": {},
      "outputs": [],
      "source": [
        "#### Replace \"NaN\" with the linear value in the \"Avg_price\" column\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "55d7cbd7-f002-4c13-aa37-d59dd89086b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Avg_price\"].interpolate(method='linear', inplace=True)\ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21f26280-9ed3-4135-bac9-f5819b3be472",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now let`s check if \"Avg_price\" column have Nan values:"
      ]
    },
    {
      "cell_type": "code",
      "id": "6aea32c0-1419-482c-a01f-507a5e275f7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data = df.isnull()\nprint(\"Avg_price\")\nprint (missing_data[\"Avg_price\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebe3dd04-7e8c-443e-bb21-e8e45898ff2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "We can see there are no missed values anymore.\nNow we can fix missed values in indicators columns. We used firs 10 rows in ADOSC and NATR column to anticipate next values, so let`s drop them."
      ]
    },
    {
      "cell_type": "code",
      "id": "2d4c0e9e-e611-4403-84a6-a82cf2ca7b4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop(df.index[range(10)])\ndf.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ada5e6d-4800-4f33-89c5-29ad774d2316",
      "metadata": {},
      "outputs": [],
      "source": [
        "Now we are going to fix another Nan values in ADOSC, TRANGE and NATR columns. We will replace them by interpolated values, using different types of interpolation."
      ]
    },
    {
      "cell_type": "code",
      "id": "84da0ee7-5b8d-4d19-8c5c-287879d86083",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"ADOSC\"].interpolate(method='nearest', inplace=True)\ndf[\"TRANGE\"].interpolate(method='quadratic', inplace=True)\ndf[\"NATR\"].interpolate(method='cubic', inplace=True)\n\nindicators = [\"ADOSC\", \"TRANGE\", 'NATR']\n\nmissing_data = df.isnull()\nfor indicator in indicators:\n    print(indicator)\n    print(missing_data[indicator].value_counts())\n    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a7f373-6fb0-4368-a54a-a65b9bedfe58",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  #1: </h1>\n\n<b>Based on the example above, replace NaN in \"Close\" column with the linear interpolation value.</b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "c52c8797-10a6-4f63-855b-38642036980a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad3a605e-827e-4166-b067-98a909b124d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n\n# replace NaN by with the linear interpolation value in \"Close\" column\ndf[\"Close\"].interpolate(method='linear', inplace=True)\ndf.head(5)\n\n```\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b037b4d-9b47-48cc-83d1-a6b4c875c925",
      "metadata": {},
      "outputs": [],
      "source": [
        "Also we can use some more interpolation types like polynomial, with that type of interpolation we need to choose order, for example we use 5"
      ]
    },
    {
      "cell_type": "code",
      "id": "f04718bc-ebab-47af-994f-8b23dad1e09f",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"High\"].interpolate(method='nearest', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1097a94-1a20-4f2d-b6d5-8db6e6690bf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "The replacement result is very similar to what we have seen previously with other methods\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "d1a42c6e-52cd-454f-a074-04dc90cc215c",
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data = df.isnull()\nprint(\"High\")\nprint (missing_data[\"High\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "174a843b-56f6-4054-b424-e7a9de804ed2",
      "metadata": {},
      "outputs": [],
      "source": [
        "No more missed values in \"High\" column.\nNow we can fill Nan values in another columns:\n<li>The \"Low\" column we will fill using interpolation like we used on the \"ADOSC\" one</li>"
      ]
    },
    {
      "cell_type": "code",
      "id": "d784b4b6-5ca1-41c4-9769-6d6d95b70748",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Low\"].interpolate(method='nearest', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29e2a0f5-0c60-4090-924a-404fc33857ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "<li>The \"Open\" column we will fill like the \"High\" one, but now we will use a spline type of interpolation</li>"
      ]
    },
    {
      "cell_type": "code",
      "id": "1b5755ab-2362-4029-8b26-cf00a8988f9b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace NaN by with the linear interpolation value in \"Open\" column\ndf[\"Open\"].interpolate(method='spline', order = 3, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff179f87-71c0-493f-99c6-20573a255602",
      "metadata": {},
      "outputs": [],
      "source": [
        "Check if we fix all data"
      ]
    },
    {
      "cell_type": "code",
      "id": "9d66638c-ceb0-4493-a2db-96168dac5a8c",
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data = df.isnull()\nfor column in missing_data.columns.values.tolist():\n    print(column)\n    print (missing_data[column].value_counts())\n    print(\"\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a7182b-5db2-4e09-87f7-fe6d7d5ea6a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>Good!</b> Now, we have a dataset with no missing values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c48ac92-be51-494b-8200-880e40c02113",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Correct data format\n<b>We are almost there!</b>\n<p>The last step in data cleaning is checking and making sure that all data is in the correct format (int, float, text or other).</p>\n\nIn Pandas, we use:\n\n<p><b>.dtype()</b> to check the data type</p>\n<p><b>.astype()</b> to change the data type</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2245c11-4090-4d1b-81c3-62bfe1a11906",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Let's list the data types for each column</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "b957a9f5-2551-4f1b-ae40-50b0b28ca217",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "947e8f13-8cb0-4cf8-b552-4919d16b9a7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>As we can see above, some columns are not of the correct data type. Numerical variables should have type 'float' or 'int', and variables with strings such as categories should have type 'object'. We have to convert data types into a proper format for each column using the \"astype()\" method.</p> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f29ce1b-f8c5-427a-b8e8-cbb3a9efe828",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Convert data types to proper format</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "989eaf3f-d745-43b1-a2ef-ec1ff0398ef5",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[[\"Volume\"]] = df[[\"Volume\"]].astype(\"int\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a20f74-92e5-47bf-89d3-ba87239649e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "<h4>Let us list the columns after the conversion</h4>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "5e445cd6-6fec-4aec-a4a1-2dccf15ff100",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b4b47ec-bdd5-4b5e-b550-e1e01f39b190",
      "metadata": {},
      "outputs": [],
      "source": [
        "<b>Wonderful!</b>\n\nNow we have finally obtained the cleaned dataset with no missing values with all data in its proper format.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9c4092c9-912b-41b9-a78a-a5a4de9f1a88",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv('MATICBUSD_lab3.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaecd06-f17d-465c-8def-6930148a908d",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Data Standardization\n<p>\nData is usually collected from different agencies in different formats.\n(Data standardization is also a term for a particular type of data normalization where we subtract the mean and divide by the standard deviation.)\n</p>\n\n<b>What is standardization?</b>\n\n<p>Standardization is the process of transforming data into a common format, allowing the researcher to make the meaningful comparison.\n</p>\n\n<b>Example</b>\n\n<p>Transform USD to EUR:</p>\n<p>In our dataset, the columns with price values are represented by BUSD. Assume we are developing an application in a country that accepts the price values with EUR standard.</p>\n<p>We will need to apply <b>data transformation</b> to transform BUSD into EUR.</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9e07038c-47cb-43d2-b90c-4a1ed5c5e6e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "id": "7b4b388f-c327-4501-8345-18cf1bc77eb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n# Convert mpg to USDT by mathematical operation\nres = requests.get(\"https://api.binance.com/sapi/v1/convert/exchangeInfo?fromAsset=BUSD&toAsset=EUR\")\nif res.status_code != 200:\n    rate = 0.93\nelse:\n    res = res.json()\n    rate = float(res[0][\"toAssetMinAmount\"])\n    \nprint(f\"The exchange rate is 1 BUSD = {rate} EUR\")\n\ncols_to_convert = [\"Open\", \"High\", \"Low\", \"Close\", \"Avg_price\"]\nfor col in cols_to_convert:\n    df[f\"{col}_EUR\"] = df[col] * rate\n\n# check your transformed data \ndf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f081e094-e786-43e1-9570-ee408eea763d",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  #2: </h1>\n\n<b>According to the example above, transform BUSD to GBP in \"Avg_price\" column and change the name of columns in appropriative way.</b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "38c9f6bb-43b4-468a-9927-4ee6cbd945f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b428dc-86ec-4d94-bdbb-ee2cafeef550",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n# Convert BUSD to GBP by mathematical operation\n\nimport requests\n# Convert mpg to USDT by mathematical operation\nres = requests.get(\"https://api.binance.com/sapi/v1/convert/exchangeInfo?fromAsset=BUSD&toAsset=GBP\")\nif res.status_code != 200:\n    rate = 0.83\nelse:\n    res = res.json()\n    rate = float(res[0][\"toAssetMinAmount\"])\n    \nprint(f\"The exchange rate is 1 BUSD = {rate} GBP\")\n\ncols_to_convert = [\"Open\", \"High\", \"Low\", \"Close\", \"Avg_price\"]\nfor col in cols_to_convert:\n    df[f\"{col}_GBP\"] = df[col] * rate\n\n# check your transformed data \ndf.head()\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67d29466-c8ae-465a-b582-80e47290c1f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Data Normalization\n\n<b>Why normalization?</b>\n\n<p>Normalization is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, scaling the variable so the variance is 1, or scaling the variable so the variable values range from 0 to 1.\n</p>\n\n<b>Example</b>\n\n<p>To demonstrate normalization, let's say we want to scale the columns \"Open\" and \"Close\".</p>\n<p><b>Target:</b> would like to normalize those variables so their value ranges from 0 to 1</p>\n<p><b>Approach:</b> replace original value by (original value)/(maximum value)</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2bbf74b6-35a7-4a03-a44e-b69c51da251b",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "id": "c07f46bd-e374-4765-8501-a0746feb0fa3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace (original value) by (original value)/(maximum value)\ndf['Open'] = df['Open']/df['Open'].max()\ndf['Close'] = df['Close']/df['Close'].max()\ndf.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b391e9c1-0834-445d-b06c-12ec20fce663",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question #3: </h1>\n\n<b>According to the example above, normalize the column \"Avg_price\".</b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "2b6b623a-41af-4f35-b050-bae809dd8aba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5e45685-8a4f-45b2-bc22-754fb1f00fa5",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\ndf['Avg_price'] = df['Avg_price']/df['Avg_price'].max() \n\n# show the scaled columns\ndf[[\"Open\",\"Close\",\"Avg_price\"]].head()\n\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e25d101-bbff-46ae-adc4-695dc6d412d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "Here we can see we've normalized \"Open\", \"Close\" and \"Avg_price\" in the range of \\[0,1].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b41c83c-67fa-4b67-999a-d863cb06e938",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Binning\n<b>Why binning?</b>\n<p>\n    Binning is a process of transforming continuous numerical variables into discrete categorical 'bins' for grouped analysis.\n</p>\n\n<b>Example: </b>\n\n<p>In our dataset, \"Avg_price\" is a real valued variable ranging from 0.7661862 to 1.064339 and it has a lot unique values. What if we only care about the price difference between DOGE in diapasone with high Avg_price, medium Avg_price, and little Avg_price (3 types)? Can we rearrange them into three ‘bins' to simplify analysis? </p>\n\n<p>We will use the pandas method 'cut' to segment the 'Avg_price' column into 3 bins.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef0f73df-9d5d-476c-934a-699af377e064",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Example of Binning Data In Pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "710b6488-0971-4330-b6d0-395aa99b60ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "Convert data to correct format:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f9d222d2-c498-48a0-8276-b72ba73b55ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Avg_price\"]=df[\"Avg_price\"].astype(float, copy=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea0ec51a-1f09-4de5-ad59-747fccf059ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's plot the histogram of Avg_price to see what the distribution of Avg_price looks like.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "85e1f95b-ed97-4208-a071-51ff7368f698",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.pyplot.hist(df[\"Avg_price\"])\n\n# set x/y labels and plot title\nplt.pyplot.xlabel(\"Avg_price\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"Avg_price bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4befa5f4-c6ef-4c85-b443-903c86785331",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>We would like 3 bins of equal size bandwidth so we use numpy's <code>linspace(start_value, end_value, numbers_generated</code> function.</p>\n<p>Since we want to include the minimum value of Avg_price, we want to set start_value = min(df[\"Avg_price\"]).</p>\n<p>Since we want to include the maximum value of Avg_price, we want to set end_value = max(df[\"Avg_price\"]).</p>\n<p>Since we are building 3 bins of equal length, there should be 4 dividers, so numbers_generated = 4.</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41794da8-d0c6-4ef7-af41-d4cb71b2ed57",
      "metadata": {},
      "outputs": [],
      "source": [
        "We build a bin array with a minimum value to a maximum value by using the bandwidth calculated above. The values will determine when one bin ends and another begins.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "6472e551-e637-483a-b585-f871d0fd513f",
      "metadata": {},
      "outputs": [],
      "source": [
        "bins = np.linspace(min(df[\"Avg_price\"]), max(df[\"Avg_price\"]), 4)\nbins"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9eee984-e4af-4575-b1a1-fd91e5e17a71",
      "metadata": {},
      "outputs": [],
      "source": [
        "We set group  names:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "29e33398-4cb3-4647-9dfd-aab30647a917",
      "metadata": {},
      "outputs": [],
      "source": [
        "group_names = ['Low', 'Medium', 'High']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d52a8574-e523-47b6-92e8-4076c4c733df",
      "metadata": {},
      "outputs": [],
      "source": [
        "We apply the function \"cut\" to determine what each value of `df['Avg_price']` belongs to.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "832db38b-b816-4f6e-8e5f-f4bb7569ee85",
      "metadata": {},
      "outputs": [],
      "source": [
        "df['Avg_price-binned'] = pd.cut(df['Avg_price'], bins, labels=group_names, include_lowest=True )\ndf[['Avg_price','Avg_price-binned']].head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e556130e-c785-41bd-9100-96fd882d5fde",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's see the number of data in each bin:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "dcf55035-c1ba-424a-aaa6-227406b83a65",
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"Avg_price-binned\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f853aee-3494-4ec5-83d7-65f8daa8ff6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "Let's plot the distribution of each bin:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "9fac5e20-0b7c-4fb9-b84d-a90ad98abda7",
      "metadata": {},
      "outputs": [],
      "source": [
        "pyplot.bar(group_names, df[\"Avg_price-binned\"].value_counts())\n\n# set x/y labels and plot title\nplt.pyplot.xlabel(\"Avg_price\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"Avg_price bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8401b54-c7aa-4503-bc7b-09d402e85cd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<p>\n    Look at the dataframe above carefully. You will find that the last column provides the bins for \"Avg_price\" based on 3 categories (\"Low\", \"Medium\" and \"High\"). \n</p>\n<p>\n    We successfully narrowed down the intervals to only 3!\n</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1291383b-ebdb-431b-ae58-79f2ce5e9341",
      "metadata": {},
      "outputs": [],
      "source": [
        "### Bins Visualization\nNormally, a histogram is used to visualize the distribution of bins we created above. \n"
      ]
    },
    {
      "cell_type": "code",
      "id": "f2992bf0-642b-4e70-b921-d2a4bc8c222d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# draw historgram of attribute \"horsepower\" with bins = 3\nplt.pyplot.hist(df[\"Avg_price\"], bins = 3)\n\n# set x/y labels and plot title\nplt.pyplot.xlabel(\"Avg_price\")\nplt.pyplot.ylabel(\"count\")\nplt.pyplot.title(\"Avg_price bins\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d797dc2-9f02-43ed-83d6-117ad353a2ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "The plot above shows the binning result for the attribute \"Avg_price\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc3c1d6-5c8c-4684-87f9-151af085f5fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Indicator Variable (or Dummy Variable)\n<b>What is an indicator variable?</b>\n<p>\n    An indicator variable (or dummy variable) is a numerical variable used to label categories. They are called 'dummies' because the numbers themselves don't have inherent meaning. \n</p>\n\n<b>Why we use indicator variables?</b>\n\n<p>\n    We use indicator variables so we can use categorical variables for regression analysis in the later modules.\n</p>\n<b>Example</b>\n<p>\n    We see the column \"Avg_price\" has three unique values: \"Low\", \"Medium\" or \"High\". Regression doesn't understand words, only numbers. To use this attribute in regression analysis, we convert \"Avg_price\" to indicator variables.\n</p>\n\n<p>\n    We will use pandas' method 'get_dummies' to assign numerical values to different categories of Avg_price. \n</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a50ed55f-3554-4f3f-8620-37bbe01a5fc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc36984-6342-4120-a78e-1ec1762bb726",
      "metadata": {},
      "outputs": [],
      "source": [
        "Get the indicator variables and assign it to data frame \"dummy_variable\\_1\":\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e9680802-d978-4229-960e-7fd71764007c",
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_variable_1 = pd.get_dummies(df[\"Avg_price-binned\"])\ndummy_variable_1.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68872b20-56e0-444d-9e52-3f4f6f0a9589",
      "metadata": {},
      "outputs": [],
      "source": [
        "Change the column names for clarity:\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "bceb6f88-b497-47c2-996a-3b0715c1acd4",
      "metadata": {},
      "outputs": [],
      "source": [
        "dummy_variable_1.rename(columns={'Low':'Avg_price-Low', 'Medium':'Avg_price-Medium', 'High':'Avg_price-High'}, inplace=True)\ndummy_variable_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2fa68c-c6ae-4177-b6c4-fde102269258",
      "metadata": {},
      "outputs": [],
      "source": [
        "In the dataframe, column 'Avg_price' has values for 'Low', 'Medium' and 'High' as 0s and 1s now.\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "ec011076-af82-4dfd-82d4-a084620520f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# merge data frame \"df\" and \"dummy_variable_1\" \ndf = pd.concat([df, dummy_variable_1], axis=1)\n\n# drop original column \"Avg_price\" from \"df\"\ndf.drop(\"Avg_price\", axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "id": "a93c5212-e02b-41ae-944c-7037fc9736a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c28275-6554-4476-ab38-c69a05f994dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "The last two columns are now the indicator variable representation of the Avg_price variable. They're all 0s and 1s now.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8930d67-22d5-4ef8-b680-501da543e54e",
      "metadata": {},
      "outputs": [],
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  #4: </h1>\n\n<b>Similar to before, create an indicator variable for the column \"Ts\"</b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "8883f528-9ccf-48ee-aa0c-06f6db6e63e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cb425e1-c902-48dc-88d0-571d8cf5bfd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\n# get day name\nday = df.Ts\ndf['Day_name'] = day.df.day_name()\n\n# get indicator variables of aspiration and assign it to data frame \"dummy_variable_2\"\ndummy_variable_2 = pd.get_dummies(df['Day_name'])\n\n# show first 5 instances of data frame \"dummy_variable_1\"\ndummy_variable_2.head()\n\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5b3867-625b-4eda-ae0c-30c9e5e3b9f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Resample time series data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a23d05-8467-4f51-bc3d-8c32deb71217",
      "metadata": {},
      "outputs": [],
      "source": [
        "Resampling is a series of techniques used in statistics to gather more information about a sample. This can include retaking a sample or estimating its accuracy. With these additional techniques, resampling often improves the overall accuracy and estimates any uncertainty within a population."
      ]
    },
    {
      "cell_type": "code",
      "id": "2e31406e-db46-43f2-9aaf-7bd5adc054a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "#create new dataset\nwdf = pd.DataFrame()\ndf.index = df.index.astype(\"datetime64[ns]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d381258-0873-4903-864e-2b4f587e933a",
      "metadata": {},
      "outputs": [],
      "source": [
        "Find summary Rec_count per week:"
      ]
    },
    {
      "cell_type": "code",
      "id": "e49cad52-ff04-428b-872b-4fca8484e3c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "wdf['Open'] = df['Open'].resample('D').first()\nwdf['High'] = df['High'].resample('D').max()\nwdf['Low'] = df['Low'].resample('D').min()\nwdf['Close'] = df['Close'].resample('D').last()\nwdf['Volume'] = df['Volume'].resample('D').sum()"
      ]
    },
    {
      "cell_type": "code",
      "id": "3232cd1c-cd9f-46d0-9b10-7777123ec533",
      "metadata": {},
      "outputs": [],
      "source": [
        "wdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbab6336-658a-4fde-849b-79af0134601b",
      "metadata": {},
      "outputs": [],
      "source": [
        " <div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n<h1> Question  #5: </h1>\n\n<b>Make a daily summary of Rec_count_eur.</b>\n\n</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "11d34efc-1186-41c7-b7c0-c5419feb6b53",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write your code below and press Shift+Enter to execute \n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd199bb1-d7ff-4286-97da-2402e4482876",
      "metadata": {},
      "outputs": [],
      "source": [
        "<details><summary>Click here for the solution</summary>\n\n```python\nnwdf = pd.DataFrame()\nnwdf['Open'] = df['Open'].resample('D').first()\nnwdf['High'] = df['High'].resample('D').max()\nnwdf['Low'] = df['Low'].resample('D').min()\nnwdf['Close'] = df['Close'].resample('D').last()\nnwdf['Volume'] = df = pd.DataFrame()wdf['Volume'].resample('D').sum()\nnwdf.head()\n\n```\n\n</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "a82ff4b5-4a6d-4629-969f-26592012059b",
      "metadata": {},
      "outputs": [],
      "source": [
        "wdf.to_csv('clean_df.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "982f7551-28a0-4f45-9e6e-eae3521e2823",
      "metadata": {},
      "outputs": [],
      "source": [
        "Save the new csv:\n\n> Note : The  csv file cannot be viewed in the jupyterlite based SN labs environment.However you can Click <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Module%202/DA0101EN-2-Review-Data-Wrangling.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2022-01-01\">HERE</a> to download the lab notebook (.ipynb) to your local machine and view the csv file once the notebook is executed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f288ee7-c86e-481e-b676-9711b86138f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# **Thank you for completing Lab 2!**\n\n## Authors\n\n<a href=\"https://author.skills.network/instructors/oleh_lozovyi?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Oleh Lozovyi</a>\n\n<a href=\"https://author.skills.network/instructors/yaroslav_vyklyuk_2?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Yaroslav Vyklyuk, DrSc, PhD</a>\n\n<a href=\"https://author.skills.network/instructors/mariya_fleychuk?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkGuidedProjectsIBMSkillsNetworkGPXX0QGDEN2306-2023-01-01\">Prof. Mariya Fleychuk, DrSc, PhD</a>\n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">Joseph Santarcangelo</a>\n\n\n<a href=\"https://www.linkedin.com/in/fiorellawever/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\">Fiorella Wenver</a>\n\n<a href=\"https:// https://www.linkedin.com/in/yi-leng-yao-84451275/ \" target=\"_blank\" >Yi Yao</a>\n\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By   | Change Description                                         |\n| ----------------- | ------- | -------------| ---------------------------------------------------------- |\n|     2023-03-08    |   1.0   | Oleh Lozovyi | Lab created                                                |\n\n<hr>\n\n## <h3 align=\"center\"> © IBM Corporation 2023. All rights reserved. <h3/>\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "12959ba1-939e-446c-8f75-edf40df26447",
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "",
      "display_name": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}